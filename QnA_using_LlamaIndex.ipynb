{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3895302bb2e44d8f89eb3aa5ef686027": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9e643c4494f64947b46554902a00f1f2",
              "IPY_MODEL_170d641f8bfb4a8ba62a2a999170b699",
              "IPY_MODEL_201fa89b5cb843f686bcaf4772268882"
            ],
            "layout": "IPY_MODEL_7a678e09a7864a32916e4d93093b3690"
          }
        },
        "9e643c4494f64947b46554902a00f1f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9307637d3fe940c9b77fc8604b9684c6",
            "placeholder": "​",
            "style": "IPY_MODEL_9146679d7d1d4e98b8cd1ae23f0fab29",
            "value": "Parsing nodes: 100%"
          }
        },
        "170d641f8bfb4a8ba62a2a999170b699": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2dec0b80c77c4fbd96a43ee312c77568",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_243fd894017e4afdaccd5229a959ec94",
            "value": 28
          }
        },
        "201fa89b5cb843f686bcaf4772268882": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2550e457983e4b54b9170f9ff4ae5522",
            "placeholder": "​",
            "style": "IPY_MODEL_33ca50a37eb24f87901d7843d00c7875",
            "value": " 28/28 [00:00&lt;00:00, 257.49it/s]"
          }
        },
        "7a678e09a7864a32916e4d93093b3690": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9307637d3fe940c9b77fc8604b9684c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9146679d7d1d4e98b8cd1ae23f0fab29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2dec0b80c77c4fbd96a43ee312c77568": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "243fd894017e4afdaccd5229a959ec94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2550e457983e4b54b9170f9ff4ae5522": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33ca50a37eb24f87901d7843d00c7875": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c29a13f6394a41099346f5b2744a0d89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_02dbfc6a9b454db69ee21765e6810716",
              "IPY_MODEL_e6ed8646330549c2978840203afc416e",
              "IPY_MODEL_58e87083ad2a4277b9131f30ee24f894"
            ],
            "layout": "IPY_MODEL_8101e043761b4e7e9384e2702764f3ae"
          }
        },
        "02dbfc6a9b454db69ee21765e6810716": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e60495835cb4f39b3ef9d9c3d838f27",
            "placeholder": "​",
            "style": "IPY_MODEL_bb2e873282314b708a342b8be790f9ae",
            "value": "Generating embeddings: 100%"
          }
        },
        "e6ed8646330549c2978840203afc416e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bfaaf7a9b2f413f9ebe7067c375836c",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba8e499e41f34e92a26ae84e427991f1",
            "value": 28
          }
        },
        "58e87083ad2a4277b9131f30ee24f894": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b26b340c310d4d2d88a784bb27e56ba3",
            "placeholder": "​",
            "style": "IPY_MODEL_dde75cdab0a842faa1d9e01dd607f9da",
            "value": " 28/28 [00:13&lt;00:00,  2.10it/s]"
          }
        },
        "8101e043761b4e7e9384e2702764f3ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e60495835cb4f39b3ef9d9c3d838f27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb2e873282314b708a342b8be790f9ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8bfaaf7a9b2f413f9ebe7067c375836c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba8e499e41f34e92a26ae84e427991f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b26b340c310d4d2d88a784bb27e56ba3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dde75cdab0a842faa1d9e01dd607f9da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jeremy-su1/LlamaIndex-train/blob/main/QnA_using_LlamaIndex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "PdjGaGBf77iC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "QnA using LlamaIndex, PostgreSQL, and LLama-2\n",
        "============================================"
      ],
      "metadata": {
        "id": "SeONvlDbU6tj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Drive approach\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "s9WRI9qBVG5H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76ebafe5-533d-4140-807d-4033518904ae"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.Environment Setup"
      ],
      "metadata": {
        "id": "9q2aah7-VSF-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sys 모듈을 임포트\n",
        "# sys 모듈은 파이썬 인터프리터와 관련된 함수와 변수들을 제공\n",
        "import sys\n",
        "\n",
        "# 현재 파이썬 인터프리터의 버전 정보를 출력\n",
        "sys.version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6KXus22xVQ14",
        "outputId": "2f250c1e-f30e-4e02-b8fc-fac1bcdac0c9"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## GPU 상태 확인\n",
        "!nvidia-smi  # NVIDIA 시스템 관리 인터페이스를 실행하여 GPU 상태 및 사용량 확인\n",
        "!nvidia-smi -L  # 시스템에 설치된 모든 NVIDIA GPU 리스트 출력\n",
        "!nvidia-smi -q -d memory  # GPU 메모리 사용량에 대한 상세 정보 조회\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYU6no1VV1Wn",
        "outputId": "9e9d3f3d-1075-4c74-bf4e-ea4054130890"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Mar 13 05:45:39 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n",
            "GPU 0: Tesla T4 (UUID: GPU-fb08f874-fdaf-72d4-50de-003d82b216d9)\n",
            "\n",
            "==============NVSMI LOG==============\n",
            "\n",
            "Timestamp                                 : Wed Mar 13 05:45:40 2024\n",
            "Driver Version                            : 535.104.05\n",
            "CUDA Version                              : 12.2\n",
            "\n",
            "Attached GPUs                             : 1\n",
            "GPU 00000000:00:04.0\n",
            "    FB Memory Usage\n",
            "        Total                             : 15360 MiB\n",
            "        Reserved                          : 257 MiB\n",
            "        Used                              : 0 MiB\n",
            "        Free                              : 15101 MiB\n",
            "    BAR1 Memory Usage\n",
            "        Total                             : 256 MiB\n",
            "        Used                              : 2 MiB\n",
            "        Free                              : 254 MiB\n",
            "    Conf Compute Protected Memory Usage\n",
            "        Total                             : 0 MiB\n",
            "        Used                              : 0 MiB\n",
            "        Free                              : 0 MiB\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<left>\n",
        "<img src='https://drive.google.com/uc?id=10dYBZdRtgOBbzgWmxkRX8QXOo3_rQYTS' width=\"70%\" height=\"70%\">\n",
        "</left>"
      ],
      "metadata": {
        "id": "AJJoIVLKcfUB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "① Driver Version : 현재 설치되어 사용하고 있는 nvidia GPU의 driver version  \n",
        "② CUDA Version : 현재 사용하고 있는 driver와 호환이 잘 되는 CUDA version  \n",
        "③ GPU & FAN : 현재 설치되어 있는 GPU의 번호/GPU의 fan 성능  \n",
        "  &emsp;(Tesla 계열의 GPU는 fan이 없어 N/A로 표기)\n",
        "  \n",
        "④ GPU Name, Temp, Pwr:Usage/Cap : GPU Model Name, GPU의 현재 온도를 썹씨로 표기. 보통 70~80사이가 적절  \n",
        "⑤ Memory-Usage : 현재 사용하고 있는 GPU의 memory와 GPU의 총 memory  \n",
        "⑥ GPU-Util : GPU의 현재 성능을 나타낸 것으로 100%의 성능 중 얼마만큼 사용하고 있는지를 나타냄. 즉, 현재 해당 GPU의 사용량\n",
        "⑦ Type(G/C): 2가지 type모두 GPU에 관련된 것이다.  \n",
        "&ensp;(1) G = Graphcis의 G로 그래픽을 사용하거나 video rendering을 위한 전문가용 3D 그래픽, 게임 등에서 사용되는 NVIDIA GPU의 graphic-mode를 사용하는 process를 의미한다.  \n",
        "&ensp;(2) C = Compute의 C로 CUDA library를 사용하는 NVIDIA GPU의 compute-mode를 사용하는 process를 의미한다. Tensorflow나 Pytorch 등을 사용하는 deep learning의 학습과 테스트하는데 사용된다.  \n",
        "&ensp;(3) C+G = Compute+Graphic을 합친 것으로 compute-mode와 graphic-mode를 함께 사용하는 process를 의미한다."
      ],
      "metadata": {
        "id": "ILJXqaSHhqvz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.LlamaIndex Installation\n",
        "------------------\n",
        "\n",
        "\n",
        "- llama-index package내 포함되어 있는 패키지\n",
        "  - llama-index-core\n",
        "  - llama-index-legacy  # temporarily included\n",
        "  - llama-index-llms-openai\n",
        "  - llama-index-embeddings-openai\n",
        "  - llama-index-program-openai\n",
        "  - llama-index-question-gen-openai\n",
        "  - llama-index-agent-openai\n",
        "  - llama-index-readers-file\n",
        "  - llama-index-multi-modal-llms-openai"
      ],
      "metadata": {
        "id": "niDAhrx2JinO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWE2AjXAJhtR",
        "outputId": "efe088c3-902d-4bdd-852e-7dd685dae6a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index\n",
            "  Downloading llama_index-0.10.19-py3-none-any.whl (5.6 kB)\n",
            "Collecting llama-index-agent-openai<0.2.0,>=0.1.4 (from llama-index)\n",
            "  Downloading llama_index_agent_openai-0.1.5-py3-none-any.whl (12 kB)\n",
            "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index)\n",
            "  Downloading llama_index_cli-0.1.9-py3-none-any.whl (25 kB)\n",
            "Collecting llama-index-core<0.11.0,>=0.10.19 (from llama-index)\n",
            "  Downloading llama_index_core-0.10.20-py3-none-any.whl (15.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index)\n",
            "  Downloading llama_index_embeddings_openai-0.1.6-py3-none-any.whl (6.0 kB)\n",
            "Collecting llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 (from llama-index)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.1.4-py3-none-any.whl (6.6 kB)\n",
            "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n",
            "  Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-llms-openai<0.2.0,>=0.1.5 (from llama-index)\n",
            "  Downloading llama_index_llms_openai-0.1.10-py3-none-any.whl (10.0 kB)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.1.4-py3-none-any.whl (5.8 kB)\n",
            "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index)\n",
            "  Downloading llama_index_program_openai-0.1.4-py3-none-any.whl (4.1 kB)\n",
            "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index)\n",
            "  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
            "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index)\n",
            "  Downloading llama_index_readers_file-0.1.11-py3-none-any.whl (36 kB)\n",
            "Collecting llama-index-readers-llama-parse<0.2.0,>=0.1.2 (from llama-index)\n",
            "  Downloading llama_index_readers_llama_parse-0.1.3-py3-none-any.whl (2.5 kB)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index) (3.9.3)\n",
            "Collecting dataclasses-json (from llama-index-core<0.11.0,>=0.10.19->llama-index)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.11.0,>=0.10.19->llama-index)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.11.0,>=0.10.19->llama-index)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index) (2023.6.0)\n",
            "Collecting httpx (from llama-index-core<0.11.0,>=0.10.19->llama-index)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llamaindex-py-client<0.2.0,>=0.1.13 (from llama-index-core<0.11.0,>=0.10.19->llama-index)\n",
            "  Downloading llamaindex_py_client-0.1.13-py3-none-any.whl (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index) (3.2.1)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index) (1.25.2)\n",
            "Collecting openai>=1.1.0 (from llama-index-core<0.11.0,>=0.10.19->llama-index)\n",
            "  Downloading openai-1.14.0-py3-none-any.whl (257 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.5/257.5 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index) (1.5.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index) (8.2.3)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core<0.11.0,>=0.10.19->llama-index)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index) (4.10.0)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.11.0,>=0.10.19->llama-index)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\n",
            "Collecting bs4<0.0.3,>=0.0.2 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Collecting pymupdf<2.0.0,>=1.23.21 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
            "  Downloading PyMuPDF-1.23.26-cp310-none-manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
            "  Downloading pypdf-4.1.0-py3-none-any.whl (286 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.1/286.1 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Collecting llama-parse<0.4.0,>=0.3.3 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index)\n",
            "  Downloading llama_parse-0.3.9-py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.19->llama-index) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.19->llama-index) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.19->llama-index) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.19->llama-index) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.19->llama-index) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.19->llama-index) (4.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.19->llama-index) (1.14.1)\n",
            "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.19->llama-index) (2.6.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.19->llama-index) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.19->llama-index) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx->llama-index-core<0.11.0,>=0.10.19->llama-index)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.19->llama-index) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.19->llama-index) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.19->llama-index)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.19->llama-index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.19->llama-index) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.19->llama-index) (2023.12.25)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.19->llama-index) (1.7.0)\n",
            "Collecting PyMuPDFb==1.23.22 (from pymupdf<2.0.0,>=1.23.21->llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
            "  Downloading PyMuPDFb-1.23.22-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.19->llama-index) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.19->llama-index) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.19->llama-index) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.19->llama-index)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.11.0,>=0.10.19->llama-index)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.19->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.19->llama-index) (2023.4)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.19->llama-index) (1.2.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.19->llama-index) (24.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.19->llama-index) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.19->llama-index) (2.16.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->llama-index-core<0.11.0,>=0.10.19->llama-index) (1.16.0)\n",
            "Installing collected packages: striprtf, dirtyjson, pypdf, PyMuPDFb, mypy-extensions, marshmallow, h11, deprecated, typing-inspect, tiktoken, pymupdf, httpcore, bs4, httpx, dataclasses-json, openai, llamaindex-py-client, llama-index-legacy, llama-index-core, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
            "Successfully installed PyMuPDFb-1.23.22 bs4-0.0.2 dataclasses-json-0.6.4 deprecated-1.2.14 dirtyjson-1.0.8 h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 llama-index-0.10.19 llama-index-agent-openai-0.1.5 llama-index-cli-0.1.9 llama-index-core-0.10.20 llama-index-embeddings-openai-0.1.6 llama-index-indices-managed-llama-cloud-0.1.4 llama-index-legacy-0.9.48 llama-index-llms-openai-0.1.10 llama-index-multi-modal-llms-openai-0.1.4 llama-index-program-openai-0.1.4 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.11 llama-index-readers-llama-parse-0.1.3 llama-parse-0.3.9 llamaindex-py-client-0.1.13 marshmallow-3.21.1 mypy-extensions-1.0.0 openai-1.14.0 pymupdf-1.23.26 pypdf-4.1.0 striprtf-0.0.26 tiktoken-0.6.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "# LlamaIndex package 설치\n",
        "!pip install llama-index"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# llama-index 설치 패키지 확인\n",
        "print(f'Llama-index check')\n",
        "!pip show llama-index\n",
        "\n",
        "print(\"\")\n",
        "# Llama-Index 포함 패키지 확인\n",
        "print(f'Llama-index dbundle package check')\n",
        "!pip list | egrep 'llama-index-core|llama-index-readers-file|llama-index-multi-modal-llms-openai'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dETLQ-3Qxbo",
        "outputId": "3da08531-7d58-4961-9697-219c78f88a3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Llama-index check\n",
            "Name: llama-index\n",
            "Version: 0.10.19\n",
            "Summary: Interface between LLMs and your data\n",
            "Home-page: https://llamaindex.ai\n",
            "Author: Jerry Liu\n",
            "Author-email: jerry@llamaindex.ai\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: llama-index-agent-openai, llama-index-cli, llama-index-core, llama-index-embeddings-openai, llama-index-indices-managed-llama-cloud, llama-index-legacy, llama-index-llms-openai, llama-index-multi-modal-llms-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index-readers-file, llama-index-readers-llama-parse\n",
            "Required-by: \n",
            "\n",
            "Llama-index dbundle package check\n",
            "llama-index-core                        0.10.19\n",
            "llama-index-multi-modal-llms-openai     0.1.4\n",
            "llama-index-readers-file                0.1.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import sys\n",
        "\n",
        "#Uncomment to see debug logs\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
        "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
      ],
      "metadata": {
        "id": "0Ji7RmvTMiSI"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.Sentence Embedding"
      ],
      "metadata": {
        "id": "0sQXAXaDJoeT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Documents"
      ],
      "metadata": {
        "id": "-hsjQzAEEwXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# llama_index library포함\n",
        "# https://llamahub.ai/l/readers/llama-index-readers-file?from=\n",
        "#\n",
        "from llama_index.readers.file import PDFReader\n",
        "# PDFReader 인스턴스를 생성\n",
        "reader = PDFReader()"
      ],
      "metadata": {
        "id": "6WxM8_oIEbPt"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download Document  \n",
        "SCP 설치형DB(Installed DB) 백업 가이드  \n",
        "https://drive.google.com/file/d/1zIn4wneO2vn9A3T7PdUa9ECMHMv7Y4av/view?usp=drive_link"
      ],
      "metadata": {
        "id": "dfhr3zGeCbvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p 'data/scp/'\n",
        "!wget -O 'data/scp/scp_data.pdf' 'https://drive.google.com/uc?export=download&id=1zIn4wneO2vn9A3T7PdUa9ECMHMv7Y4av'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVMWfqD2EH0N",
        "outputId": "c7d178ef-342d-45e3-daf1-b9ee9dc84066"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-15 11:55:14--  https://drive.google.com/uc?export=download&id=1zIn4wneO2vn9A3T7PdUa9ECMHMv7Y4av\n",
            "Resolving drive.google.com (drive.google.com)... 142.250.145.102, 142.250.145.139, 142.250.145.138, ...\n",
            "Connecting to drive.google.com (drive.google.com)|142.250.145.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1zIn4wneO2vn9A3T7PdUa9ECMHMv7Y4av&export=download [following]\n",
            "--2024-03-15 11:55:15--  https://drive.usercontent.google.com/download?id=1zIn4wneO2vn9A3T7PdUa9ECMHMv7Y4av&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 172.217.218.132, 2a00:1450:4013:c08::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|172.217.218.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1244224 (1.2M) [application/octet-stream]\n",
            "Saving to: ‘data/scp/scp_data.pdf’\n",
            "\n",
            "data/scp/scp_data.p 100%[===================>]   1.19M  --.-KB/s    in 0.009s  \n",
            "\n",
            "2024-03-15 11:55:16 (135 MB/s) - ‘data/scp/scp_data.pdf’ saved [1244224/1244224]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PDF파일로부터 데이터 로드\n",
        "documents = reader.load_data('./data/scp/scp_data.pdf')"
      ],
      "metadata": {
        "id": "A9ZJBaXbFQtV"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10번째 문서의 ID와 text내용 출력\n",
        "print(f'document id: {documents[9].doc_id}')\n",
        "print(f'text: {documents[9].text}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WucDrdDSJ6Rz",
        "outputId": "db0f1752-f1c3-4d7a-955a-b042117556dd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "document id: 42a7a9f0-d9a5-498e-9987-1fab69e08b5c\n",
            "text:  \n",
            " Copyright 2023. Samsung SDS Inc. All rights reserved  \n",
            " \n",
            "7 3. File System Emulated Tools - s3fs 사용법  \n",
            "s3fs 는 Object Storage 를  서버에  mount 해서 사용하도록  지원하는  툴로서 , Object \n",
            "Storage 를 File System 처럼 사용할  수 있어 편리합니다 .  \n",
            "아래 표는 s3fs 기본 사용법 에 대한 설명입니다.  \n",
            "상세한  사용법은  s3fs 설명서를  참고하세요 .    \n",
            "https://github.com/s3fs -fuse/s3fs -fuse  \n",
            "설치 # yum install epel -release  \n",
            "# yum install s3fs -fuse  \n",
            "설정 설정파일에  Object Stroage access_key:secret_key 정보 입력합니다 . \n",
            "# vi ${HOME}/.passwd -s3fs  \n",
            "38xxxxxxxxxxxxxxxxx0:43xxxxxxxxxxxxxxxxxxxxx7  \n",
            "mount  아래와  같이 s3fs 를 실행하면  됩니다 . \n",
            "# s3fs ${BACKUP_S3_BUCKET} ${MOUNT_PATH} \\ \n",
            "-o passwd_file=${HOME}/.passwd -s3fs \\ \n",
            "-o url=${BACKUP_S3_ENDPOINT} \\ \n",
            "-o parallel_count=10 \\ \n",
            "-o multipart_size=20 \\ \n",
            "-o ensure_diskfree=5120 \\ \n",
            "-o del_cache -o use_cache=/cache_dir \\ \n",
            "-o use_path_request_style \\ \n",
            "-o allow_other \\ \n",
            "-o no_check_certificate \\ \n",
            "-o nonem pty \\ \n",
            "-o nomixupload  \n",
            " \n",
            "<< 주의 사항 >> \n",
            "* Cache Disk 공간은 root  와 별도 FileSystem 으로 분리 \n",
            "umount  umount 하면 s3fs 프로세스가  종료됩니다 . \n",
            "# umount /s3fs  \n",
            " \n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# openai api key 사용시에 수행\n",
        "import os\n",
        "import openai\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"COPY AND PASTE YOUR OPENAI API HERE\"\n",
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
      ],
      "metadata": {
        "id": "1u_dOK_URGbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.Install PostgreSQL server & pgvector"
      ],
      "metadata": {
        "id": "YWXVEkFLFhxe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## postgreSQL 설치"
      ],
      "metadata": {
        "id": "zNBIkkVXAlE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"sqlalchemy[asyncio]\" psycopg2 pgvector asyncpg greenlet"
      ],
      "metadata": {
        "id": "y6VNPia3Iz0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a26b0cc1-eea1-4a98-f7c6-9cbf9f8f76a7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sqlalchemy[asyncio] in /usr/local/lib/python3.10/dist-packages (2.0.28)\n",
            "Requirement already satisfied: psycopg2 in /usr/local/lib/python3.10/dist-packages (2.9.9)\n",
            "Requirement already satisfied: pgvector in /usr/local/lib/python3.10/dist-packages (0.2.5)\n",
            "Requirement already satisfied: asyncpg in /usr/local/lib/python3.10/dist-packages (0.29.0)\n",
            "Requirement already satisfied: greenlet in /usr/local/lib/python3.10/dist-packages (3.0.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy[asyncio]) (4.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pgvector) (1.25.2)\n",
            "Requirement already satisfied: async-timeout>=4.0.3 in /usr/local/lib/python3.10/dist-packages (from asyncpg) (4.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# llama-index와 PostgreSQL을 연동하여 벡터 데이터를 저장 및 관리 기능 제공\n",
        "%pip install llama-index-vector-stores-postgres"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWcgVvEQFVTm",
        "outputId": "cf8651a1-8354-4c8f-ca5d-011514df371a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index-vector-stores-postgres\n",
            "  Downloading llama_index_vector_stores_postgres-0.1.3-py3-none-any.whl (6.3 kB)\n",
            "Collecting asyncpg<0.30.0,>=0.29.0 (from llama-index-vector-stores-postgres)\n",
            "  Downloading asyncpg-0.29.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-vector-stores-postgres) (0.10.20)\n",
            "Collecting pgvector<0.3.0,>=0.2.4 (from llama-index-vector-stores-postgres)\n",
            "  Downloading pgvector-0.2.5-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting psycopg2-binary<3.0.0,>=2.9.9 (from llama-index-vector-stores-postgres)\n",
            "  Downloading psycopg2_binary-2.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy[asyncio]<3.0.0,>=2.0.25 in /usr/local/lib/python3.10/dist-packages (from llama-index-vector-stores-postgres) (2.0.28)\n",
            "Requirement already satisfied: async-timeout>=4.0.3 in /usr/local/lib/python3.10/dist-packages (from asyncpg<0.30.0,>=0.29.0->llama-index-vector-stores-postgres) (4.0.3)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (6.0.1)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (3.9.3)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (0.6.4)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (2023.6.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (0.27.0)\n",
            "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.13 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (0.1.13)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (3.2.1)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (1.25.2)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (1.14.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (1.5.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (8.2.3)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (4.10.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (0.9.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy[asyncio]<3.0.0,>=2.0.25->llama-index-vector-stores-postgres) (3.0.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (1.9.4)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (1.14.1)\n",
            "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (2.6.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (1.0.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (0.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (2023.12.25)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (1.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (2.0.7)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (3.21.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (2023.4)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (1.2.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (24.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (2.16.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-postgres) (1.16.0)\n",
            "Installing collected packages: psycopg2-binary, pgvector, asyncpg, llama-index-vector-stores-postgres\n",
            "Successfully installed asyncpg-0.29.0 llama-index-vector-stores-postgres-0.1.3 pgvector-0.2.5 psycopg2-binary-2.9.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 참고 사항\n",
        "%lsmagic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "9YRF1VrE_ONR",
        "outputId": "65f8d449-3d5f-4bea-8530-21bf23d265a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Available line magics:\n",
              "%alias  %alias_magic  %autoawait  %autocall  %automagic  %autosave  %bookmark  %cat  %cd  %clear  %colors  %conda  %config  %connect_info  %cp  %debug  %dhist  %dirs  %doctest_mode  %ed  %edit  %env  %gui  %hist  %history  %killbgscripts  %ldir  %less  %lf  %lk  %ll  %load  %load_ext  %loadpy  %logoff  %logon  %logstart  %logstate  %logstop  %ls  %lsmagic  %lx  %macro  %magic  %man  %matplotlib  %mkdir  %more  %mv  %notebook  %page  %pastebin  %pdb  %pdef  %pdoc  %pfile  %pinfo  %pinfo2  %pip  %popd  %pprint  %precision  %prun  %psearch  %psource  %pushd  %pwd  %pycat  %pylab  %qtconsole  %quickref  %recall  %rehashx  %reload_ext  %rep  %rerun  %reset  %reset_selective  %rm  %rmdir  %run  %save  %sc  %set_env  %shell  %store  %sx  %system  %tb  %tensorflow_version  %time  %timeit  %unalias  %unload_ext  %who  %who_ls  %whos  %xdel  %xmode\n",
              "\n",
              "Available cell magics:\n",
              "%%!  %%HTML  %%SVG  %%bash  %%bigquery  %%capture  %%debug  %%file  %%html  %%javascript  %%js  %%latex  %%markdown  %%perl  %%prun  %%pypy  %%python  %%python2  %%python3  %%ruby  %%script  %%sh  %%shell  %%svg  %%sx  %%system  %%time  %%timeit  %%writefile\n",
              "\n",
              "Automagic is ON, % prefix IS NOT needed for line magics."
            ],
            "application/json": {
              "line": {
                "automagic": "AutoMagics",
                "autocall": "AutoMagics",
                "alias_magic": "BasicMagics",
                "lsmagic": "BasicMagics",
                "magic": "BasicMagics",
                "page": "BasicMagics",
                "pprint": "BasicMagics",
                "colors": "BasicMagics",
                "xmode": "BasicMagics",
                "quickref": "BasicMagics",
                "doctest_mode": "BasicMagics",
                "gui": "BasicMagics",
                "precision": "BasicMagics",
                "notebook": "BasicMagics",
                "save": "CodeMagics",
                "pastebin": "CodeMagics",
                "loadpy": "CodeMagics",
                "load": "CodeMagics",
                "edit": "KernelMagics",
                "config": "ConfigMagics",
                "prun": "ExecutionMagics",
                "pdb": "ExecutionMagics",
                "debug": "ExecutionMagics",
                "tb": "ExecutionMagics",
                "run": "ExecutionMagics",
                "timeit": "ExecutionMagics",
                "time": "ExecutionMagics",
                "macro": "ExecutionMagics",
                "load_ext": "ExtensionMagics",
                "unload_ext": "ExtensionMagics",
                "reload_ext": "ExtensionMagics",
                "history": "HistoryMagics",
                "recall": "HistoryMagics",
                "rerun": "HistoryMagics",
                "logstart": "LoggingMagics",
                "logstop": "LoggingMagics",
                "logoff": "LoggingMagics",
                "logon": "LoggingMagics",
                "logstate": "LoggingMagics",
                "pinfo": "NamespaceMagics",
                "pinfo2": "NamespaceMagics",
                "pdef": "NamespaceMagics",
                "pdoc": "NamespaceMagics",
                "psource": "NamespaceMagics",
                "pfile": "NamespaceMagics",
                "psearch": "NamespaceMagics",
                "who_ls": "NamespaceMagics",
                "who": "NamespaceMagics",
                "whos": "NamespaceMagics",
                "reset": "NamespaceMagics",
                "reset_selective": "NamespaceMagics",
                "xdel": "NamespaceMagics",
                "alias": "OSMagics",
                "unalias": "OSMagics",
                "rehashx": "OSMagics",
                "pwd": "OSMagics",
                "cd": "OSMagics",
                "env": "OSMagics",
                "set_env": "OSMagics",
                "pushd": "OSMagics",
                "popd": "OSMagics",
                "dirs": "OSMagics",
                "dhist": "OSMagics",
                "sc": "OSMagics",
                "sx": "OSMagics",
                "system": "OSMagics",
                "bookmark": "OSMagics",
                "pycat": "OSMagics",
                "pip": "Other",
                "conda": "PackagingMagics",
                "matplotlib": "PylabMagics",
                "pylab": "PylabMagics",
                "killbgscripts": "ScriptMagics",
                "autoawait": "AsyncMagics",
                "ed": "Other",
                "hist": "Other",
                "rep": "Other",
                "clear": "KernelMagics",
                "less": "KernelMagics",
                "more": "KernelMagics",
                "man": "KernelMagics",
                "connect_info": "KernelMagics",
                "qtconsole": "KernelMagics",
                "autosave": "KernelMagics",
                "mkdir": "Other",
                "rmdir": "Other",
                "mv": "Other",
                "rm": "Other",
                "cp": "Other",
                "cat": "Other",
                "ls": "Other",
                "ll": "Other",
                "lf": "Other",
                "lk": "Other",
                "ldir": "Other",
                "lx": "Other",
                "store": "StoreMagics",
                "shell": "Other",
                "tensorflow_version": "Other"
              },
              "cell": {
                "js": "DisplayMagics",
                "javascript": "DisplayMagics",
                "latex": "DisplayMagics",
                "svg": "DisplayMagics",
                "html": "DisplayMagics",
                "markdown": "DisplayMagics",
                "prun": "ExecutionMagics",
                "debug": "ExecutionMagics",
                "timeit": "ExecutionMagics",
                "time": "ExecutionMagics",
                "capture": "ExecutionMagics",
                "sx": "OSMagics",
                "system": "OSMagics",
                "!": "OSMagics",
                "writefile": "OSMagics",
                "script": "ScriptMagics",
                "sh": "Other",
                "bash": "Other",
                "perl": "Other",
                "ruby": "Other",
                "python": "Other",
                "python2": "Other",
                "python3": "Other",
                "pypy": "Other",
                "SVG": "Other",
                "HTML": "Other",
                "file": "Other",
                "bigquery": "Other",
                "shell": "Other"
              }
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# postgresql 패키지, postgresql 15버전 설치 및 가동\n",
        "!sudo apt update\n",
        "!sudo apt install -y postgresql-common\n",
        "!echo | sudo /usr/share/postgresql-common/pgdg/apt.postgresql.org.sh\n",
        "!sudo apt install postgresql-15-pgvector\n",
        "!sudo service postgresql start"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7Zu23hBE78S",
        "outputId": "dfd53db8-432c-4a9e-946a-c61d74ed1f6d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\u001b[33m\r0% [Connecting to security.ubuntu.com (91.189.91.81)] [Connected to cloud.r-pro\u001b[0m\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "\r                                                                               \rGet:3 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "\r                                                                               \rGet:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "\r                                                                               \rGet:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,848 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,998 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,354 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1,961 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,079 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,569 kB]\n",
            "Fetched 10.2 MB in 4s (2,694 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "40 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libcommon-sense-perl libjson-perl libjson-xs-perl libtypes-serialiser-perl\n",
            "  logrotate netbase postgresql-client-common ssl-cert\n",
            "Suggested packages:\n",
            "  bsd-mailx | mailx\n",
            "The following NEW packages will be installed:\n",
            "  libcommon-sense-perl libjson-perl libjson-xs-perl libtypes-serialiser-perl\n",
            "  logrotate netbase postgresql-client-common postgresql-common ssl-cert\n",
            "0 upgraded, 9 newly installed, 0 to remove and 40 not upgraded.\n",
            "Need to get 485 kB of archives.\n",
            "After this operation, 1,716 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 logrotate amd64 3.19.0-1ubuntu1.1 [54.3 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 netbase all 6.3 [12.9 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libcommon-sense-perl amd64 3.75-2build1 [21.1 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjson-perl all 4.04000-1 [81.8 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libtypes-serialiser-perl all 1.01-1 [11.6 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjson-xs-perl amd64 4.030-1build3 [87.2 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 postgresql-client-common all 238 [29.6 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 ssl-cert all 1.1.2 [17.4 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 postgresql-common all 238 [169 kB]\n",
            "Fetched 485 kB in 0s (4,443 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 9.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package logrotate.\n",
            "(Reading database ... 121752 files and directories currently installed.)\n",
            "Preparing to unpack .../0-logrotate_3.19.0-1ubuntu1.1_amd64.deb ...\n",
            "Unpacking logrotate (3.19.0-1ubuntu1.1) ...\n",
            "Selecting previously unselected package netbase.\n",
            "Preparing to unpack .../1-netbase_6.3_all.deb ...\n",
            "Unpacking netbase (6.3) ...\n",
            "Selecting previously unselected package libcommon-sense-perl:amd64.\n",
            "Preparing to unpack .../2-libcommon-sense-perl_3.75-2build1_amd64.deb ...\n",
            "Unpacking libcommon-sense-perl:amd64 (3.75-2build1) ...\n",
            "Selecting previously unselected package libjson-perl.\n",
            "Preparing to unpack .../3-libjson-perl_4.04000-1_all.deb ...\n",
            "Unpacking libjson-perl (4.04000-1) ...\n",
            "Selecting previously unselected package libtypes-serialiser-perl.\n",
            "Preparing to unpack .../4-libtypes-serialiser-perl_1.01-1_all.deb ...\n",
            "Unpacking libtypes-serialiser-perl (1.01-1) ...\n",
            "Selecting previously unselected package libjson-xs-perl.\n",
            "Preparing to unpack .../5-libjson-xs-perl_4.030-1build3_amd64.deb ...\n",
            "Unpacking libjson-xs-perl (4.030-1build3) ...\n",
            "Selecting previously unselected package postgresql-client-common.\n",
            "Preparing to unpack .../6-postgresql-client-common_238_all.deb ...\n",
            "Unpacking postgresql-client-common (238) ...\n",
            "Selecting previously unselected package ssl-cert.\n",
            "Preparing to unpack .../7-ssl-cert_1.1.2_all.deb ...\n",
            "Unpacking ssl-cert (1.1.2) ...\n",
            "Selecting previously unselected package postgresql-common.\n",
            "Preparing to unpack .../8-postgresql-common_238_all.deb ...\n",
            "Adding 'diversion of /usr/bin/pg_config to /usr/bin/pg_config.libpq-dev by postgresql-common'\n",
            "Unpacking postgresql-common (238) ...\n",
            "Setting up logrotate (3.19.0-1ubuntu1.1) ...\n",
            "Created symlink /etc/systemd/system/timers.target.wants/logrotate.timer → /lib/systemd/system/logrotate.timer.\n",
            "Setting up libcommon-sense-perl:amd64 (3.75-2build1) ...\n",
            "Setting up ssl-cert (1.1.2) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Setting up libtypes-serialiser-perl (1.01-1) ...\n",
            "Setting up libjson-perl (4.04000-1) ...\n",
            "Setting up netbase (6.3) ...\n",
            "Setting up postgresql-client-common (238) ...\n",
            "Setting up libjson-xs-perl (4.030-1build3) ...\n",
            "Setting up postgresql-common (238) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Adding user postgres to group ssl-cert\n",
            "\n",
            "Creating config file /etc/postgresql-common/createcluster.conf with new version\n",
            "Building PostgreSQL dictionaries from installed myspell/hunspell packages...\n",
            "Removing obsolete dictionary files:\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/postgresql.service → /lib/systemd/system/postgresql.service.\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "This script will enable the PostgreSQL APT repository on apt.postgresql.org on\n",
            "your system. The distribution codename used will be jammy-pgdg.\n",
            "\n",
            "Press Enter to continue, or Ctrl-C to abort.\n",
            "Writing /etc/apt/sources.list.d/pgdg.list ...\n",
            "Importing repository signing key ...\n",
            "Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n",
            "OK\n",
            "\n",
            "Running apt-get update ...\n",
            "Get:1 http://apt.postgresql.org/pub/repos/apt jammy-pgdg InRelease [123 kB]\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://apt.postgresql.org/pub/repos/apt jammy-pgdg/main amd64 Packages [488 kB]\n",
            "Fetched 611 kB in 1s (440 kB/s)\n",
            "Reading package lists... Done\n",
            "\n",
            "You can now start installing packages from apt.postgresql.org.\n",
            "\n",
            "Have a look at https://wiki.postgresql.org/wiki/Apt for more information;\n",
            "most notably the FAQ at https://wiki.postgresql.org/wiki/Apt/FAQ\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpq-dev libpq5 postgresql-15 postgresql-client-15 postgresql-client-common\n",
            "  postgresql-common sysstat\n",
            "Suggested packages:\n",
            "  postgresql-doc-16 postgresql-doc-15 isag\n",
            "The following NEW packages will be installed:\n",
            "  postgresql-15 postgresql-15-pgvector postgresql-client-15 sysstat\n",
            "The following packages will be upgraded:\n",
            "  libpq-dev libpq5 postgresql-client-common postgresql-common\n",
            "4 upgraded, 4 newly installed, 0 to remove and 40 not upgraded.\n",
            "Need to get 20.1 MB of archives.\n",
            "After this operation, 65.2 MB of additional disk space will be used.\n",
            "Get:1 http://apt.postgresql.org/pub/repos/apt jammy-pgdg/main amd64 postgresql-common all 257.pgdg22.04+1 [239 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 sysstat amd64 12.5.2-2ubuntu0.2 [487 kB]\n",
            "Get:3 http://apt.postgresql.org/pub/repos/apt jammy-pgdg/main amd64 postgresql-client-common all 257.pgdg22.04+1 [94.3 kB]\n",
            "Get:4 http://apt.postgresql.org/pub/repos/apt jammy-pgdg/main amd64 libpq-dev amd64 16.2-1.pgdg22.04+1 [142 kB]\n",
            "Get:5 http://apt.postgresql.org/pub/repos/apt jammy-pgdg/main amd64 libpq5 amd64 16.2-1.pgdg22.04+1 [214 kB]\n",
            "Get:6 http://apt.postgresql.org/pub/repos/apt jammy-pgdg/main amd64 postgresql-client-15 amd64 15.6-1.pgdg22.04+1 [1,686 kB]\n",
            "Get:7 http://apt.postgresql.org/pub/repos/apt jammy-pgdg/main amd64 postgresql-15 amd64 15.6-1.pgdg22.04+1 [17.1 MB]\n",
            "Get:8 http://apt.postgresql.org/pub/repos/apt jammy-pgdg/main amd64 postgresql-15-pgvector amd64 0.6.1-1.pgdg22.04+1 [199 kB]\n",
            "Fetched 20.1 MB in 0s (78.2 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 8.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "(Reading database ... 122001 files and directories currently installed.)\n",
            "Preparing to unpack .../0-postgresql-common_257.pgdg22.04+1_all.deb ...\n",
            "Leaving 'diversion of /usr/bin/pg_config to /usr/bin/pg_config.libpq-dev by postgresql-common'\n",
            "Unpacking postgresql-common (257.pgdg22.04+1) over (238) ...\n",
            "Preparing to unpack .../1-postgresql-client-common_257.pgdg22.04+1_all.deb ...\n",
            "Unpacking postgresql-client-common (257.pgdg22.04+1) over (238) ...\n",
            "Preparing to unpack .../2-libpq-dev_16.2-1.pgdg22.04+1_amd64.deb ...\n",
            "Unpacking libpq-dev (16.2-1.pgdg22.04+1) over (14.11-0ubuntu0.22.04.1) ...\n",
            "Preparing to unpack .../3-libpq5_16.2-1.pgdg22.04+1_amd64.deb ...\n",
            "Unpacking libpq5:amd64 (16.2-1.pgdg22.04+1) over (14.11-0ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package postgresql-client-15.\n",
            "Preparing to unpack .../4-postgresql-client-15_15.6-1.pgdg22.04+1_amd64.deb ...\n",
            "Unpacking postgresql-client-15 (15.6-1.pgdg22.04+1) ...\n",
            "Selecting previously unselected package postgresql-15.\n",
            "Preparing to unpack .../5-postgresql-15_15.6-1.pgdg22.04+1_amd64.deb ...\n",
            "Unpacking postgresql-15 (15.6-1.pgdg22.04+1) ...\n",
            "Selecting previously unselected package postgresql-15-pgvector.\n",
            "Preparing to unpack .../6-postgresql-15-pgvector_0.6.1-1.pgdg22.04+1_amd64.deb ...\n",
            "Unpacking postgresql-15-pgvector (0.6.1-1.pgdg22.04+1) ...\n",
            "Selecting previously unselected package sysstat.\n",
            "Preparing to unpack .../7-sysstat_12.5.2-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking sysstat (12.5.2-2ubuntu0.2) ...\n",
            "Setting up postgresql-client-common (257.pgdg22.04+1) ...\n",
            "Installing new version of config file /etc/postgresql-common/supported_versions ...\n",
            "Setting up libpq5:amd64 (16.2-1.pgdg22.04+1) ...\n",
            "Setting up postgresql-client-15 (15.6-1.pgdg22.04+1) ...\n",
            "update-alternatives: using /usr/share/postgresql/15/man/man1/psql.1.gz to provide /usr/share/man/man1/psql.1.gz (psql.1.gz) in auto mode\n",
            "Setting up libpq-dev (16.2-1.pgdg22.04+1) ...\n",
            "Setting up postgresql-common (257.pgdg22.04+1) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Replacing config file /etc/postgresql-common/createcluster.conf with new version\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up sysstat (12.5.2-2ubuntu0.2) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "\n",
            "Creating config file /etc/default/sysstat with new version\n",
            "update-alternatives: using /usr/bin/sar.sysstat to provide /usr/bin/sar (sar) in auto mode\n",
            "Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-collect.timer → /lib/systemd/system/sysstat-collect.timer.\n",
            "Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-summary.timer → /lib/systemd/system/sysstat-summary.timer.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/sysstat.service → /lib/systemd/system/sysstat.service.\n",
            "Setting up postgresql-15 (15.6-1.pgdg22.04+1) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Creating new PostgreSQL cluster 15/main ...\n",
            "/usr/lib/postgresql/15/bin/initdb -D /var/lib/postgresql/15/main --auth-local peer --auth-host scram-sha-256 --no-instructions\n",
            "The files belonging to this database system will be owned by user \"postgres\".\n",
            "This user must also own the server process.\n",
            "\n",
            "The database cluster will be initialized with locale \"en_US.UTF-8\".\n",
            "The default database encoding has accordingly been set to \"UTF8\".\n",
            "The default text search configuration will be set to \"english\".\n",
            "\n",
            "Data page checksums are disabled.\n",
            "\n",
            "fixing permissions on existing directory /var/lib/postgresql/15/main ... ok\n",
            "creating subdirectories ... ok\n",
            "selecting dynamic shared memory implementation ... posix\n",
            "selecting default max_connections ... 100\n",
            "selecting default shared_buffers ... 128MB\n",
            "selecting default time zone ... Etc/UTC\n",
            "creating configuration files ... ok\n",
            "running bootstrap script ... ok\n",
            "performing post-bootstrap initialization ... ok\n",
            "syncing data to disk ... ok\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up postgresql-15-pgvector (0.6.1-1.pgdg22.04+1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            " * Starting PostgreSQL 15 database server\n",
            "   ...done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### postgreSQL database 생성"
      ],
      "metadata": {
        "id": "2LehjxawAtCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup a password 'postgres' for username\n",
        "!sudo -u postgres psql -c \"ALTER USER postgres PASSWORD 'password';\"\n",
        "# vector_db 이름의 database 생성\n",
        "!sudo -u postgres psql -c \"CREATE DATABASE vector_db;\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzYHI1faFBTD",
        "outputId": "5adcfbc9-482c-4c22-f3bb-60b80ed52ca3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ALTER ROLE\n",
            "CREATE DATABASE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SimpleDirectoryReader는 디렉토리 내의 파일들을 읽는 데 사용되며, StorageContext는 저장소의 컨텍스트를 관리\n",
        "from llama_index.core import SimpleDirectoryReader, StorageContext\n",
        "\n",
        "# VectorStoreIndex는 벡터 저장소를 인덱싱하고 관리하는 데 사용\n",
        "from llama_index.core import VectorStoreIndex\n",
        "\n",
        "# PGVectorStore는 PostgreSQL을 사용하여 벡터 데이터를 저장하고 검색하는 구현을 제공\n",
        "from llama_index.vector_stores.postgres import PGVectorStore\n",
        "\n",
        "# Python의 표준 라이브러리인 textwrap 모듈은 텍스트를 특정 너비에 맞게 포맷팅하는 데 사용\n",
        "import textwrap\n",
        "\n",
        "# OpenAI의 API를 사용하기 위한 openai 라이브러리를 임포트\n",
        "import openai\n"
      ],
      "metadata": {
        "id": "qRpTJVsjHEYQ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Establish Connection"
      ],
      "metadata": {
        "id": "e8cl7YseD6Gc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# psycopg2 : Python에서 PostgreSQL 데이터베이스를 조작하기 위한 기능\n",
        "# python 표준 라이브러리\n",
        "import psycopg2\n",
        "\n",
        "# PostgreSQL 데이터베이스에 연결하기 위한 변수 할당 및 DB이름 변수 할당\n",
        "connection_string = \"postgresql://postgres:password@localhost:5432\"\n",
        "db_name = \"vector_db\"\n",
        "\n",
        "# psycopg2.connect() 함수를 사용하여 PostgreSQL 데이터베이스에 연결\n",
        "conn = psycopg2.connect(connection_string)\n",
        "\n",
        "# 데이터베이스 명령어가 실행되자마자 바로 반영되도록 autocommit 모드를 활성화\n",
        "# 이 옵션을 사용하지 않으면, 트랜잭션을 명시적으로 커밋해야 변경사항이 데이터베이스에 반영\n",
        "conn.autocommit = True\n",
        "\n",
        "# 데이터베이스 커서를 사용하여 SQL 명령을 실행합니다.\n",
        "# with 구문을 사용함으로써 커서 사용이 끝나면 자동으로 리소스가 정리됩니다.\n",
        "with conn.cursor() as c:\n",
        "    c.execute(f\"DROP DATABASE IF EXISTS {db_name}\")\n",
        "    c.execute(f\"CREATE DATABASE {db_name}\")\n"
      ],
      "metadata": {
        "id": "I24XpQoQG2Xh"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Database 확인해보기"
      ],
      "metadata": {
        "id": "6yh_ka4vESt3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set connection\n",
        "%env DATABASE_URL=postgresql://postgres:password@localhost:5432/vector_db"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2C2ZCNI-HBTd",
        "outputId": "91adde9a-7fc3-4de2-f6d3-e5126aabcbbc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: DATABASE_URL=postgresql://postgres:password@localhost:5432/vector_db\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To load the sql extention to start using %%sql\n",
        "%load_ext sql"
      ],
      "metadata": {
        "id": "AIX2IXDmMuqR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cda172f0-ffc2-40b8-e355-2c6027a34b6f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sql extension is already loaded. To reload it, use:\n",
            "  %reload_ext sql\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# You can start executing postgres sql commands\n",
        "%%sql\n",
        "SELECT version();\n",
        "SELECT current_database();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "id": "OhPUwJX4M1Af",
        "outputId": "7dc78a7e-09ce-4189-b8aa-7de878db3ca5"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * postgresql://postgres:***@localhost:5432/vector_db\n",
            "1 rows affected.\n",
            "1 rows affected.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('vector_db',)]"
            ],
            "text/html": [
              "<table>\n",
              "    <thead>\n",
              "        <tr>\n",
              "            <th>current_database</th>\n",
              "        </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "        <tr>\n",
              "            <td>vector_db</td>\n",
              "        </tr>\n",
              "    </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PGvector 생성"
      ],
      "metadata": {
        "id": "CFNTz_E2QNpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "CREATE EXTENSION IF NOT EXISTS vector;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvYdfipZNCNz",
        "outputId": "1cb66e1f-9a5c-4e2c-c91a-3d8d2dad5689"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * postgresql://postgres:***@localhost:5432/vector_db\n",
            "Done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.Install required python modules"
      ],
      "metadata": {
        "id": "3IoiNPlbQTZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# llama-hub 및 llmx(textgenerator)\n",
        "#!pip install llama-hub llmx\n",
        "!pip install llama-hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aoBzC5EQKYy",
        "outputId": "4c249924-77a1-4386-9129-65b578e061db"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-hub\n",
            "  Downloading llama_hub-0.0.79.post1-py3-none-any.whl (103.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.9/103.9 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llmx\n",
            "  Downloading llmx-0.0.21a0-py3-none-any.whl (20 kB)\n",
            "Collecting html2text (from llama-hub)\n",
            "  Downloading html2text-2024.2.26.tar.gz (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: llama-index>=0.9.41 in /usr/local/lib/python3.10/dist-packages (from llama-hub) (0.10.19)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from llama-hub) (5.9.5)\n",
            "Collecting pyaml<24.0.0,>=23.9.7 (from llama-hub)\n",
            "  Downloading pyaml-23.12.0-py3-none-any.whl (23 kB)\n",
            "Collecting retrying (from llama-hub)\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from llmx) (2.6.3)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (from llmx) (1.14.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from llmx) (0.6.0)\n",
            "Collecting diskcache (from llmx)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cohere (from llmx)\n",
            "  Downloading cohere-4.56-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google.auth in /usr/local/lib/python3.10/dist-packages (from llmx) (2.27.0)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.10/dist-packages (from llmx) (0.9.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from llmx) (6.0.1)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.2.0,>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.9.41->llama-hub) (0.1.5)\n",
            "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.9.41->llama-hub) (0.1.9)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.19 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.9.41->llama-hub) (0.10.20)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.9.41->llama-hub) (0.1.6)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.9.41->llama-hub) (0.1.4)\n",
            "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.9.41->llama-hub) (0.9.48)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.9.41->llama-hub) (0.1.10)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.9.41->llama-hub) (0.1.4)\n",
            "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.9.41->llama-hub) (0.1.4)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.9.41->llama-hub) (0.1.3)\n",
            "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.9.41->llama-hub) (0.1.11)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse<0.2.0,>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from llama-index>=0.9.41->llama-hub) (0.1.3)\n",
            "Requirement already satisfied: aiohttp<4.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from cohere->llmx) (3.9.3)\n",
            "Collecting backoff<3.0,>=2.0 (from cohere->llmx)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting fastavro<2.0,>=1.8 (from cohere->llmx)\n",
            "  Downloading fastavro-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib_metadata<7.0,>=6.0 (from cohere->llmx)\n",
            "  Downloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from cohere->llmx) (2.31.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from cohere->llmx) (2.0.7)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google.auth->llmx) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google.auth->llmx) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google.auth->llmx) (4.9)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai->llmx) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai->llmx) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai->llmx) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai->llmx) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai->llmx) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai->llmx) (4.10.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->llmx) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic->llmx) (2.16.3)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from retrying->llama-hub) (1.16.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->llmx) (2023.12.25)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer->llmx) (8.1.7)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere->llmx) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere->llmx) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere->llmx) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere->llmx) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere->llmx) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere->llmx) (4.0.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai->llmx) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai->llmx) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai->llmx) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai->llmx) (1.0.4)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->llmx) (0.14.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata<7.0,>=6.0->cohere->llmx) (3.17.0)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index>=0.9.41->llama-hub) (2.0.28)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index>=0.9.41->llama-hub) (0.6.4)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index>=0.9.41->llama-hub) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index>=0.9.41->llama-hub) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index>=0.9.41->llama-hub) (2023.6.0)\n",
            "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.13 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index>=0.9.41->llama-hub) (0.1.13)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index>=0.9.41->llama-hub) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index>=0.9.41->llama-hub) (3.2.1)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index>=0.9.41->llama-hub) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index>=0.9.41->llama-hub) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index>=0.9.41->llama-hub) (1.5.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index>=0.9.41->llama-hub) (9.4.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index>=0.9.41->llama-hub) (8.2.3)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.19->llama-index>=0.9.41->llama-hub) (0.9.0)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index>=0.9.41->llama-hub) (4.12.3)\n",
            "Requirement already satisfied: bs4<0.0.3,>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index>=0.9.41->llama-hub) (0.0.2)\n",
            "Requirement already satisfied: pymupdf<2.0.0,>=1.23.21 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index>=0.9.41->llama-hub) (1.23.26)\n",
            "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index>=0.9.41->llama-hub) (4.1.0)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index>=0.9.41->llama-hub) (0.0.26)\n",
            "Requirement already satisfied: llama-parse<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index>=0.9.41->llama-hub) (0.3.9)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google.auth->llmx) (0.5.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere->llmx) (3.3.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index>=0.9.41->llama-hub) (2.5)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.19->llama-index>=0.9.41->llama-hub) (1.14.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.19->llama-index>=0.9.41->llama-hub) (1.3.2)\n",
            "Requirement already satisfied: PyMuPDFb==1.23.22 in /usr/local/lib/python3.10/dist-packages (from pymupdf<2.0.0,>=1.23.21->llama-index-readers-file<0.2.0,>=0.1.4->llama-index>=0.9.41->llama-hub) (1.23.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.19->llama-index>=0.9.41->llama-hub) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.19->llama-index>=0.9.41->llama-hub) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.19->llama-index>=0.9.41->llama-hub) (3.21.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.19->llama-index>=0.9.41->llama-hub) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.19->llama-index>=0.9.41->llama-hub) (2023.4)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.19->llama-index>=0.9.41->llama-hub) (24.0)\n",
            "Building wheels for collected packages: html2text\n",
            "  Building wheel for html2text (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for html2text: filename=html2text-2024.2.26-py3-none-any.whl size=33111 sha256=8d91fa17dd71594d693d0f023255972b9f8389b5f835c2fa87916db2ab33b2ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/96/6d/a7eba8f80d31cbd188a2787b81514d82fc5ae6943c44777659\n",
            "Successfully built html2text\n",
            "Installing collected packages: retrying, pyaml, importlib_metadata, html2text, fastavro, diskcache, backoff, cohere, llmx, llama-hub\n",
            "  Attempting uninstall: importlib_metadata\n",
            "    Found existing installation: importlib_metadata 7.0.2\n",
            "    Uninstalling importlib_metadata-7.0.2:\n",
            "      Successfully uninstalled importlib_metadata-7.0.2\n",
            "Successfully installed backoff-2.2.1 cohere-4.56 diskcache-5.6.3 fastavro-1.9.4 html2text-2024.2.26 importlib_metadata-6.11.0 llama-hub-0.0.79.post1 llmx-0.0.21a0 pyaml-23.12.0 retrying-1.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sentence_transformers : 사전 훈련된 모델을 사용하여 문장 또는 문단을 벡터로 변환하는 기능을 제공\n",
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bF-8X8_SQo6C",
        "outputId": "82132f04-e77a-4f4d-8f7b-80a13d70e136"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence_transformers\n",
            "  Downloading sentence_transformers-2.5.1-py3-none-any.whl (156 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/156.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/156.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.38.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (24.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.4.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence_transformers\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 sentence_transformers-2.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# python bindings for llama.cpp\n",
        "\n",
        "#https://docs.llamaindex.ai/en/stable/examples/llm/llama_2_llama_cpp.html\n",
        "%pip install llama-index-llms-llama-cpp"
      ],
      "metadata": {
        "id": "eJlTZXu7Qt3U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3751122-cc25-4cd4-da39-b370d957e8c5"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-cpp-python in /usr/local/lib/python3.10/dist-packages (0.2.56)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (4.10.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (1.25.2)\n",
            "Requirement already satisfied: diskcache>=5.6.1 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (5.6.3)\n",
            "Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8NZrxWgHKYV",
        "outputId": "ebdd0ea8-9229-482c-f611-80088a26ee55"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.12-py3-none-any.whl (809 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/809.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.3/809.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m788.5/809.1 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m809.1/809.1 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.4)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.28 (from langchain)\n",
            "  Downloading langchain_community-0.0.28-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.31 (from langchain)\n",
            "  Downloading langchain_core-0.1.32-py3-none-any.whl (260 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.9/260.9 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.26-py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.31->langchain) (3.7.1)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.31->langchain)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.31->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.31->langchain) (1.2.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Installing collected packages: packaging, orjson, jsonpointer, jsonpatch, langsmith, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.12 langchain-community-0.0.28 langchain-core-0.1.32 langchain-text-splitters-0.0.1 langsmith-0.1.26 orjson-3.9.15 packaging-23.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Llama cpp + python  \n",
        "LLAMA2 모델을 GPU가 없는 환경에서도 사용할 수 있도록 하는 GGML 프로젝트가 존재  \n",
        "GPU 자원이 많지 않은 환경에서도 사용할 수 있음"
      ],
      "metadata": {
        "id": "3M_KWDVyHoNC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.Data 전처리"
      ],
      "metadata": {
        "id": "c-ISsOEtLyXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# llama_index의 SentenceSplitter를 임포트합\n",
        "# 문서를 문장 단위로 분할하는 데 사용\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "\n",
        "# SentenceSplitter 인스턴스를 생성\n",
        "# chunk_size: 각 청크의 최대 길이를 지정\n",
        "# chunk_overlap: 청크 간 겹치는 부분의 길이를 지정\n",
        "# separator: 문장을 분리할 때 사용할 구분자를 지정\n",
        "# paragraph_separator: 단락을 분리할 때 사용할 구분자를 지정\n",
        "# secondary_chunking_regex: 추가적인 청킹을 위한 정규 표현식을 지정\n",
        "node_parser = SentenceSplitter(\n",
        "    chunk_size=1024,\n",
        "    chunk_overlap=60,\n",
        "    separator= \" \",\n",
        "    paragraph_separator=\"\\n\",\n",
        "    secondary_chunking_regex = '[^,.;。？！]+[,.;。？！]?',\n",
        ")\n",
        "\n",
        "# PDFReader로 읽어들인 문서 데이터를 사용하여 문장 단위의 노드를 생성\n",
        "nodes = node_parser.get_nodes_from_documents(documents)\n"
      ],
      "metadata": {
        "id": "GD_dirY7FVhJ"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Node Parser](https://docs.llamaindex.ai/en/stable/api_reference/service_context/node_parser.html)  \n",
        "[SentenceSplitter](https://docs.llamaindex.ai/en/stable/api/llama_index.core.node_parser.SentenceSplitter.html)  \n",
        "[TokenTextSplitter](https://docs.llamaindex.ai/en/stable/api/llama_index.core.node_parser.TokenTextSplitter.html)  \n"
      ],
      "metadata": {
        "id": "7xIEKPqiKSrZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 결과 확인\n",
        "print(nodes[9].get_content(metadata_mode=\"all\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3I_-J6r3FhnH",
        "outputId": "6f277f13-8a0a-45f7-b914-ec41193dd391"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_label: 10\n",
            "file_name: /content/data/scp/scp_data.pdf\n",
            "\n",
            "Copyright 2023. Samsung SDS Inc. All rights reserved  \n",
            " \n",
            "7 3. File System Emulated Tools - s3fs 사용법  \n",
            "s3fs 는 Object Storage 를  서버에  mount 해서 사용하도록  지원하는  툴로서 , Object \n",
            "Storage 를 File System 처럼 사용할  수 있어 편리합니다 .  \n",
            "아래 표는 s3fs 기본 사용법 에 대한 설명입니다.  \n",
            "상세한  사용법은  s3fs 설명서를  참고하세요 .    \n",
            "https://github.com/s3fs -fuse/s3fs -fuse  \n",
            "설치 # yum install epel -release  \n",
            "# yum install s3fs -fuse  \n",
            "설정 설정파일에  Object Stroage access_key:secret_key 정보 입력합니다 . \n",
            "# vi ${HOME}/.passwd -s3fs  \n",
            "38xxxxxxxxxxxxxxxxx0:43xxxxxxxxxxxxxxxxxxxxx7  \n",
            "mount  아래와  같이 s3fs 를 실행하면  됩니다 . \n",
            "# s3fs ${BACKUP_S3_BUCKET} ${MOUNT_PATH} \\ \n",
            "-o passwd_file=${HOME}/.passwd -s3fs \\ \n",
            "-o url=${BACKUP_S3_ENDPOINT} \\ \n",
            "-o parallel_count=10 \\ \n",
            "-o multipart_size=20 \\ \n",
            "-o ensure_diskfree=5120 \\ \n",
            "-o del_cache -o use_cache=/cache_dir \\ \n",
            "-o use_path_request_style \\ \n",
            "-o allow_other \\ \n",
            "-o no_check_certificate \\ \n",
            "-o nonem pty \\ \n",
            "-o nomixupload  \n",
            " \n",
            "<< 주의 사항 >> \n",
            "* Cache Disk 공간은 root  와 별도 FileSystem 으로 분리 \n",
            "umount  umount 하면 s3fs 프로세스가  종료됩니다 . \n",
            "# umount /s3fs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.pre-trained 모델 사용"
      ],
      "metadata": {
        "id": "1TP3WRc0M62i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "# 사용할 사전 훈련된 모델 이름\n",
        "# https://huggingface.co/spaces/mteb/leaderboard\n",
        "MODEL_NAME = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\" # dim : 768\n",
        "\n",
        "# GPU를 사용할 수 있으면 'cuda', 그 외는 'cpu'\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# huggingface embedding instance 생성. 모델과 인코딩 관련 설정\n",
        "embed_model = HuggingFaceEmbeddings(\n",
        "    model_name=MODEL_NAME,\n",
        "    model_kwargs={\"device\": device},\n",
        "    encode_kwargs={\"normalize_embeddings\": True}\n",
        ")\n"
      ],
      "metadata": {
        "id": "zA8JddTUCKbi"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_tmp = embed_model.embed_query(\"Hello Transformers.\")\n",
        "EMBED_DIM = len(embedding_tmp)\n",
        "print(EMBED_DIM)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5I0expKcIBDj",
        "outputId": "7bb0dfdb-8035-4851-e3a2-d95314d2caf5"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy import insert, create_engine, String, text, Integer, make_url\n",
        "\n",
        "connect_string = \"postgresql://postgres:password@localhost:5432/vector_db\"\n",
        "url = make_url(connect_string)\n",
        "\n",
        "print(\"Connection string:\", url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grju-GrIIO-U",
        "outputId": "704e7360-8a59-41db-c741-e0fdc6e7223d"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connection string: postgresql://postgres:***@localhost:5432/vector_db\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.vector_stores.postgres import PGVectorStore\n",
        "\n",
        "TABLE_NAME = \"text_embedding\"\n",
        "\n",
        "vector_store = PGVectorStore.from_params(\n",
        "    database=db_name,\n",
        "    host=url.host,\n",
        "    port=url.port,\n",
        "    user=url.username,\n",
        "    password=url.password,\n",
        "    table_name=TABLE_NAME,\n",
        "    embed_dim=EMBED_DIM,\n",
        ")\n",
        "\n",
        "## storage Context\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n"
      ],
      "metadata": {
        "id": "-dMagwwTJS82"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Llama-2 LLM from HuggingFace"
      ],
      "metadata": {
        "id": "jtUqcKw4Lk2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/models"
      ],
      "metadata": {
        "id": "FlXROORFLhQC"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmbnBjfTLtA6",
        "outputId": "286ba9d9-7587-4357-d578-d9f5985aa100"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/TheBloke/Llama-2-13B-Chat-GGUF/resolve/main/llama-2-13b-chat.Q4_K_M.gguf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2mlI5mOL36J",
        "outputId": "a5842f03-f261-4199-b41e-7dbde300cb63"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-15 13:14:30--  https://huggingface.co/TheBloke/Llama-2-13B-Chat-GGUF/resolve/main/llama-2-13b-chat.Q4_K_M.gguf\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.103, 18.239.50.49, 18.239.50.80, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.103|:443... connected.\n",
            "HTTP request sent, awaiting response... 307 Temporary Redirect\n",
            "Location: /TheBloke/Llama-2-13B-chat-GGUF/resolve/main/llama-2-13b-chat.Q4_K_M.gguf [following]\n",
            "--2024-03-15 13:14:30--  https://huggingface.co/TheBloke/Llama-2-13B-chat-GGUF/resolve/main/llama-2-13b-chat.Q4_K_M.gguf\n",
            "Reusing existing connection to huggingface.co:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/8d/b1/8db1d1f73b4caa58e947ccbfe2fb27ac5e495c2ad8457ad299d15987aee3b520/7ddfe27f61bf994542c22aca213c46ecbd8a624cca74abff02a7b5a8c18f787f?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27llama-2-13b-chat.Q4_K_M.gguf%3B+filename%3D%22llama-2-13b-chat.Q4_K_M.gguf%22%3B&Expires=1710767670&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxMDc2NzY3MH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy84ZC9iMS84ZGIxZDFmNzNiNGNhYTU4ZTk0N2NjYmZlMmZiMjdhYzVlNDk1YzJhZDg0NTdhZDI5OWQxNTk4N2FlZTNiNTIwLzdkZGZlMjdmNjFiZjk5NDU0MmMyMmFjYTIxM2M0NmVjYmQ4YTYyNGNjYTc0YWJmZjAyYTdiNWE4YzE4Zjc4N2Y%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=kxOjeePhx2It9q98cPoCVm4DWctG39z-CEVaab2lYvNf93YCxScrxdPihQiuB3%7EgnCKWzK8aw6nPJVEx12s-IksIPrgaajVdwVz0nEgFeheZ8wbKp13o%7Et67ZA0cjV6Pi-sTecRQq-BfN5%7E%7E2ty5eSJ0dTdNGvIs1B%7EC61tW2uIlBfUaKT0zIGLzK30T1XzP%7E0ZeTWgTcOzFyqaTQ7wSdMHinIU2xg1JcOOG54QB2m9VaaS9Wv66sHaseDmRY5GT-Ovff0tgtSQ3iXyu4pqmaz8mI4BtBE-BhijaDhTJ-lEh8YNB680bBIVHAsv2oomUv19NeyOqveEmArn3HL%7E-Vw__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2024-03-15 13:14:30--  https://cdn-lfs.huggingface.co/repos/8d/b1/8db1d1f73b4caa58e947ccbfe2fb27ac5e495c2ad8457ad299d15987aee3b520/7ddfe27f61bf994542c22aca213c46ecbd8a624cca74abff02a7b5a8c18f787f?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27llama-2-13b-chat.Q4_K_M.gguf%3B+filename%3D%22llama-2-13b-chat.Q4_K_M.gguf%22%3B&Expires=1710767670&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxMDc2NzY3MH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy84ZC9iMS84ZGIxZDFmNzNiNGNhYTU4ZTk0N2NjYmZlMmZiMjdhYzVlNDk1YzJhZDg0NTdhZDI5OWQxNTk4N2FlZTNiNTIwLzdkZGZlMjdmNjFiZjk5NDU0MmMyMmFjYTIxM2M0NmVjYmQ4YTYyNGNjYTc0YWJmZjAyYTdiNWE4YzE4Zjc4N2Y%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=kxOjeePhx2It9q98cPoCVm4DWctG39z-CEVaab2lYvNf93YCxScrxdPihQiuB3%7EgnCKWzK8aw6nPJVEx12s-IksIPrgaajVdwVz0nEgFeheZ8wbKp13o%7Et67ZA0cjV6Pi-sTecRQq-BfN5%7E%7E2ty5eSJ0dTdNGvIs1B%7EC61tW2uIlBfUaKT0zIGLzK30T1XzP%7E0ZeTWgTcOzFyqaTQ7wSdMHinIU2xg1JcOOG54QB2m9VaaS9Wv66sHaseDmRY5GT-Ovff0tgtSQ3iXyu4pqmaz8mI4BtBE-BhijaDhTJ-lEh8YNB680bBIVHAsv2oomUv19NeyOqveEmArn3HL%7E-Vw__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.239.18.84, 18.239.18.94, 18.239.18.68, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.239.18.84|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7865956224 (7.3G) [binary/octet-stream]\n",
            "Saving to: ‘llama-2-13b-chat.Q4_K_M.gguf’\n",
            "\n",
            "llama-2-13b-chat.Q4 100%[===================>]   7.33G   232MB/s    in 70s     \n",
            "\n",
            "2024-03-15 13:15:40 (107 MB/s) - ‘llama-2-13b-chat.Q4_K_M.gguf’ saved [7865956224/7865956224]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install llama-index-embedding-huggingface\n",
        "%pip install llama-index-llms-llama-cpp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6M3YTwkTEEi",
        "outputId": "bc130732-6c4f-443b-8f71-b1b6942e442c"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement llama-index-embedding-huggingface (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for llama-index-embedding-huggingface\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting llama-index-llms-llama-cpp\n",
            "  Downloading llama_index_llms_llama_cpp-0.1.3-py3-none-any.whl (5.1 kB)\n",
            "Requirement already satisfied: llama-cpp-python<0.3.0,>=0.2.32 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-llama-cpp) (0.2.56)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-llama-cpp) (0.10.20)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python<0.3.0,>=0.2.32->llama-index-llms-llama-cpp) (4.10.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python<0.3.0,>=0.2.32->llama-index-llms-llama-cpp) (1.25.2)\n",
            "Requirement already satisfied: diskcache>=5.6.1 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python<0.3.0,>=0.2.32->llama-index-llms-llama-cpp) (5.6.3)\n",
            "Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python<0.3.0,>=0.2.32->llama-index-llms-llama-cpp) (3.1.3)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (3.9.3)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (0.6.4)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (2023.6.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (0.27.0)\n",
            "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.13 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (0.1.13)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (3.2.1)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (3.8.1)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.14.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.5.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (8.2.3)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (4.66.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (0.9.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (4.0.3)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.14.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.3->llama-cpp-python<0.3.0,>=0.2.32->llama-index-llms-llama-cpp) (2.1.5)\n",
            "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (2.6.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.0.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (0.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (2023.12.25)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (3.21.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (2023.4)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.2.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (23.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (2.16.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.16.0)\n",
            "Installing collected packages: llama-index-llms-llama-cpp\n",
            "Successfully installed llama-index-llms-llama-cpp-0.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://docs.llamaindex.ai/en/stable/examples/llm/llama_2_llama_cpp.html#setup-llm\n",
        "from llama_index.llms.llama_cpp import LlamaCPP\n",
        "from llama_index.llms.llama_cpp.llama_utils import (\n",
        "    messages_to_prompt,\n",
        "    completion_to_prompt,\n",
        ")\n",
        "\n",
        "llm = LlamaCPP(\n",
        "    model_url=None,\n",
        "    # optionally, you can set the path to a pre-downloaded model instead of model_url\n",
        "    model_path=\"/content/models/llama-2-13b-chat.Q4_K_M.gguf\",\n",
        "    temperature=0.1,\n",
        "    max_new_tokens=512,\n",
        "    # llama2 has a context window of 4096 tokens, but we set it lower to allow for some wiggle room\n",
        "    context_window=3900,\n",
        "    # kwargs to pass to __call__()\n",
        "    generate_kwargs={},\n",
        "    # kwargs to pass to __init__()\n",
        "    # set to at least 1 to use GPU\n",
        "    model_kwargs={\"n_gpu_layers\": 1},\n",
        "    # transform inputs into Llama2 format\n",
        "    messages_to_prompt=messages_to_prompt,\n",
        "    completion_to_prompt=completion_to_prompt,\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yNBTW_2P-13",
        "outputId": "fe0c2917-768d-44d8-cb55-22dbbb5ce190"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 19 key-value pairs and 363 tensors from /content/models/llama-2-13b-chat.Q4_K_M.gguf (version GGUF V2)\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 5120\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 40\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 13824\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 40\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 40\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 15\n",
            "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   81 tensors\n",
            "llama_model_loader: - type q4_K:  241 tensors\n",
            "llama_model_loader: - type q6_K:   41 tensors\n",
            "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
            "llm_load_print_meta: format           = GGUF V2\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 4096\n",
            "llm_load_print_meta: n_embd           = 5120\n",
            "llm_load_print_meta: n_head           = 40\n",
            "llm_load_print_meta: n_head_kv        = 40\n",
            "llm_load_print_meta: n_layer          = 40\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 1\n",
            "llm_load_print_meta: n_embd_k_gqa     = 5120\n",
            "llm_load_print_meta: n_embd_v_gqa     = 5120\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 13824\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 13B\n",
            "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
            "llm_load_print_meta: model params     = 13.02 B\n",
            "llm_load_print_meta: model size       = 7.33 GiB (4.83 BPW) \n",
            "llm_load_print_meta: general.name     = LLaMA v2\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 2 '</s>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_tensors: ggml ctx size =    0.14 MiB\n",
            "llm_load_tensors:        CPU buffer size =  7500.85 MiB\n",
            "....................................................................................................\n",
            "llama_new_context_with_model: n_ctx      = 3900\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:        CPU KV buffer size =  3046.88 MiB\n",
            "llama_new_context_with_model: KV self size  = 3046.88 MiB, K (f16): 1523.44 MiB, V (f16): 1523.44 MiB\n",
            "llama_new_context_with_model:        CPU input buffer size   =    18.65 MiB\n",
            "llama_new_context_with_model:        CPU compute buffer size =   344.69 MiB\n",
            "llama_new_context_with_model: graph splits (measure): 1\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n",
            "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '5120', 'llama.feed_forward_length': '13824', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '40', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '40', 'llama.attention.head_count_kv': '40', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\n",
            "Using fallback chat format: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index-embeddings-langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrvl1JBfWJi5",
        "outputId": "67f997f4-e2a3-42f8-b023-af596228661b"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index-embeddings-langchain\n",
            "  Downloading llama_index_embeddings_langchain-0.1.2-py3-none-any.whl (2.5 kB)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-langchain) (0.10.20)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.9.3)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.6.4)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2023.6.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.27.0)\n",
            "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.13 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.1.13)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.2.1)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.25.2)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.14.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.5.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (8.2.3)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (4.10.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.9.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (4.0.3)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.14.1)\n",
            "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2.6.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.0.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2023.12.25)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.21.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2023.4)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.2.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (23.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2.16.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.16.0)\n",
            "Installing collected packages: llama-index-embeddings-langchain\n",
            "Successfully installed llama-index-embeddings-langchain-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from llama_index.core import ServiceContext\n",
        "\n",
        "# service_context = ServiceContext.from_defaults(\n",
        "#     node_parser=node_parser,\n",
        "#     embed_model=embed_model,\n",
        "#     llm=llm,\n",
        "# )\n",
        "\n",
        "# settings\n",
        "from llama_index.core import Settings\n",
        "Settings.llm = llm\n",
        "Settings.embed_model = embed_model\n",
        "Settings.node_parser = node_parser"
      ],
      "metadata": {
        "id": "ZFg6sk5SS-vQ"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "index = VectorStoreIndex.from_documents(\n",
        "    documents,\n",
        "    storage_context=storage_context,\n",
        "    embed_model=embed_model,\n",
        "    llm=llm,\n",
        "    node_parser=node_parser,\n",
        "    #service_context=service_context,\n",
        "    show_progress=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "3895302bb2e44d8f89eb3aa5ef686027",
            "9e643c4494f64947b46554902a00f1f2",
            "170d641f8bfb4a8ba62a2a999170b699",
            "201fa89b5cb843f686bcaf4772268882",
            "7a678e09a7864a32916e4d93093b3690",
            "9307637d3fe940c9b77fc8604b9684c6",
            "9146679d7d1d4e98b8cd1ae23f0fab29",
            "2dec0b80c77c4fbd96a43ee312c77568",
            "243fd894017e4afdaccd5229a959ec94",
            "2550e457983e4b54b9170f9ff4ae5522",
            "33ca50a37eb24f87901d7843d00c7875",
            "c29a13f6394a41099346f5b2744a0d89",
            "02dbfc6a9b454db69ee21765e6810716",
            "e6ed8646330549c2978840203afc416e",
            "58e87083ad2a4277b9131f30ee24f894",
            "8101e043761b4e7e9384e2702764f3ae",
            "8e60495835cb4f39b3ef9d9c3d838f27",
            "bb2e873282314b708a342b8be790f9ae",
            "8bfaaf7a9b2f413f9ebe7067c375836c",
            "ba8e499e41f34e92a26ae84e427991f1",
            "b26b340c310d4d2d88a784bb27e56ba3",
            "dde75cdab0a842faa1d9e01dd607f9da"
          ]
        },
        "id": "8Mqp7w88V3Yr",
        "outputId": "1d890287-00f7-4ded-f8da-8c4dfa8cd5bb"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Parsing nodes:   0%|          | 0/28 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3895302bb2e44d8f89eb3aa5ef686027"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating embeddings:   0%|          | 0/28 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c29a13f6394a41099346f5b2744a0d89"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "df << SELECT * FROM data_text_embedding order by id limit 2;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oih9gqMQXYOH",
        "outputId": "928d891d-b777-4e55-ae60-794bbb145233"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * postgresql://postgres:***@localhost:5432/vector_db\n",
            "2 rows affected.\n",
            "Returning data to local variable df\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0K76cQTqYWGx",
        "outputId": "9f7f97a7-8cdd-47e0-a547-04740e14dd49"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, '0 \\n     \\n \\nDB Backup Guide  SCP 설치형 DB \\n(Installed DB)  \\n백업 가이드  \\nJuly 2023  \\nCopyright 202 3. Samsung SDS Co., Ltd. All rights reserved.  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n Technical Guide', {'page_label': '1', 'file_name': '/content/data/scp/scp_data.pdf', '_node_content': '{\"id_\": \"3c267619-cafc-42d5-80ec-25b46b92fe04\", \"embedding\": null ... (871 characters truncated) ... t_id': '66a88858-6a73-427d-b100-8701c2d07846', 'doc_id': '66a88858-6a73-427d-b100-8701c2d07846', 'ref_doc_id': '66a88858-6a73-427d-b100-8701c2d07846'}, '3c267619-cafc-42d5-80ec-25b46b92fe04', '[-0.009512326,-0.031558033,0.00016662557,6.7073466e-05,0.03896472,0.022650488,0.07974196,-0.014919087,-0.006937277,0.020074043,0.025178911,0.01694114 ... (9253 characters truncated) ... 59,-0.04023897,-0.0037514034,-0.032701496,0.013437212,0.01661327,-0.01396825,-0.01848777,0.06366654,0.010386893,0.006525388,-0.01186112,-0.026132232]'),\n",
              " (2, '연락처  \\n전력식  프로 \\n삼성SDS, 기술혁신팀  \\nrs.jeon @samsung.com   \\n \\nMariaDB/ MySQL 기술지원과   삼성그룹  주요 시스템  DBMS 성능개선을  담당하고  \\n있습니다 . \\n \\n박영철  프로 \\n삼성SDS, 기술 ... (233 characters truncated) ... cle/SQL Server/SAP \\nHANA/Tibero/Redis Database 아키텍트  역할을  수행하고  있습니다 . DBMS on Cloud 에 \\n관심이  있습니다 . \\n \\n개정이력   \\n버전 변경 일자 변경 사항 \\n1.0 2023.7 최초 작성', {'page_label': '2', 'file_name': '/content/data/scp/scp_data.pdf', '_node_content': '{\"id_\": \"84dd8a99-0238-4231-9110-b419386ff959\", \"embedding\": null ... (1136 characters truncated) ... t_id': '22a68974-5935-437a-9b06-21da7d532e83', 'doc_id': '22a68974-5935-437a-9b06-21da7d532e83', 'ref_doc_id': '22a68974-5935-437a-9b06-21da7d532e83'}, '84dd8a99-0238-4231-9110-b419386ff959', '[-0.0011328842,-0.019668212,-0.0025737598,0.01949251,0.067293204,0.008884264,0.027260354,-0.0012221384,0.05180191,0.002421094,0.019379558,0.024641559 ... (9233 characters truncated) ... .06878212,0.0060886513,-0.020720128,0.014157996,-0.012962663,-0.020051938,-0.018600719,-0.07629737,0.019677155,0.019214407,-0.014087414,-0.020143084]')]"
            ],
            "text/html": [
              "<table>\n",
              "    <thead>\n",
              "        <tr>\n",
              "            <th>id</th>\n",
              "            <th>text</th>\n",
              "            <th>metadata_</th>\n",
              "            <th>node_id</th>\n",
              "            <th>embedding</th>\n",
              "        </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "        <tr>\n",
              "            <td>1</td>\n",
              "            <td>0 <br>     <br> <br>DB Backup Guide  SCP 설치형 DB <br>(Installed DB)  <br>백업 가이드  <br>July 2023  <br>Copyright 202 3. Samsung SDS Co., Ltd. All rights reserved.  <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> Technical Guide</td>\n",
              "            <td>{&#x27;page_label&#x27;: &#x27;1&#x27;, &#x27;file_name&#x27;: &#x27;/content/data/scp/scp_data.pdf&#x27;, &#x27;_node_content&#x27;: &#x27;{&quot;id_&quot;: &quot;3c267619-cafc-42d5-80ec-25b46b92fe04&quot;, &quot;embedding&quot;: null, &quot;metadata&quot;: {&quot;page_label&quot;: &quot;1&quot;, &quot;file_name&quot;: &quot;/content/data/scp/scp_data.pdf&quot;}, &quot;excluded_embed_metadata_keys&quot;: [], &quot;excluded_llm_metadata_keys&quot;: [], &quot;relationships&quot;: {&quot;1&quot;: {&quot;node_id&quot;: &quot;66a88858-6a73-427d-b100-8701c2d07846&quot;, &quot;node_type&quot;: &quot;4&quot;, &quot;metadata&quot;: {&quot;page_label&quot;: &quot;1&quot;, &quot;file_name&quot;: &quot;/content/data/scp/scp_data.pdf&quot;}, &quot;hash&quot;: &quot;e63d9d08b93ea0e7c6c77708066476c879a57d5bbbec4d7fc375a80a5863ae88&quot;, &quot;class_name&quot;: &quot;RelatedNodeInfo&quot;}, &quot;3&quot;: {&quot;node_id&quot;: &quot;84dd8a99-0238-4231-9110-b419386ff959&quot;, &quot;node_type&quot;: &quot;1&quot;, &quot;metadata&quot;: {}, &quot;hash&quot;: &quot;383912feeaaca43182accc6da093575e65026a0cc4fed602d16e7d894869d6fc&quot;, &quot;class_name&quot;: &quot;RelatedNodeInfo&quot;}}, &quot;text&quot;: &quot;&quot;, &quot;start_char_idx&quot;: 0, &quot;end_char_idx&quot;: 174, &quot;text_template&quot;: &quot;{metadata_str}\\\\n\\\\n{content}&quot;, &quot;metadata_template&quot;: &quot;{key}: {value}&quot;, &quot;metadata_seperator&quot;: &quot;\\\\n&quot;, &quot;class_name&quot;: &quot;TextNode&quot;}&#x27;, &#x27;_node_type&#x27;: &#x27;TextNode&#x27;, &#x27;document_id&#x27;: &#x27;66a88858-6a73-427d-b100-8701c2d07846&#x27;, &#x27;doc_id&#x27;: &#x27;66a88858-6a73-427d-b100-8701c2d07846&#x27;, &#x27;ref_doc_id&#x27;: &#x27;66a88858-6a73-427d-b100-8701c2d07846&#x27;}</td>\n",
              "            <td>3c267619-cafc-42d5-80ec-25b46b92fe04</td>\n",
              "            <td>[-0.009512326,-0.031558033,0.00016662557,6.7073466e-05,0.03896472,0.022650488,0.07974196,-0.014919087,-0.006937277,0.020074043,0.025178911,0.016941143,0.026970806,0.12006513,-0.01314237,-0.036001068,0.03685742,-0.0037569061,0.05148816,0.024856836,0.02593589,-0.021032752,0.046855837,-0.04197203,-0.090244815,-0.0014603579,0.0046620904,0.00834211,-0.02512405,-0.04702251,0.030635864,0.0461552,0.06384966,0.0252169,0.006847625,-0.048639067,-0.020505084,-0.014199221,-0.02150399,0.02387857,-0.010190283,-0.0023845658,-0.029648751,-0.017610308,-0.011297112,-0.004868326,-0.065670736,0.11370592,0.07193804,-0.01787859,0.010371554,-0.011674957,0.015487922,0.007095188,0.02991226,-0.07764474,-0.01388088,0.053905785,-0.030830784,-0.0467819,0.029131815,0.041348852,-0.00064028124,0.008777698,0.050552648,-0.02575359,-0.05627023,-0.009229737,0.017306063,0.013633187,0.1702057,0.028379926,-0.03689933,-0.02876224,-0.0012376714,-0.034471303,-0.027333433,-0.007332619,0.027311277,-0.0076329433,0.001908229,-0.030706292,-0.028028103,-0.067192644,-0.042246807,0.018008582,-0.0137292445,0.024377648,0.007963296,0.0140708815,0.046464108,-0.021755382,0.0052084685,-0.031737655,0.032981414,0.03215621,0.0017164698,-0.090923116,-0.013166927,0.0017387477,0.08303286,-0.014840088,-0.021266896,0.03814347,0.022240786,0.044044934,0.013709282,0.01782659,0.050596114,0.025886001,0.10782332,-0.017411035,-0.050651573,0.04086544,0.025970018,-0.022648295,0.00765266,0.0064248075,-0.016326142,0.024194892,0.17524241,-0.018146656,-0.012932033,-0.007617677,0.016195063,0.0044442913,0.044112954,0.005483062,0.014641156,-0.006378193,-0.016193638,-0.022103565,0.0061221896,0.023404073,0.012109177,0.029205225,-0.0046347296,-0.049366534,-0.15093005,-0.004592832,-0.013124757,-0.00518748,-0.007154321,0.02927852,0.0035206042,0.021809286,-0.0054218518,0.010666007,-0.01428141,0.029435363,-0.027514111,0.013803523,-0.081993416,0.007919938,-0.010354177,0.010486554,-0.14029379,-0.011708074,-0.06988228,-0.0035655785,0.0108919665,-0.018784167,-0.062061198,0.039195128,-0.019156128,0.050242122,-0.035347305,-0.0137157375,0.056528583,-0.10426511,-0.040000997,-0.011389027,0.040525254,0.008617449,-0.021153735,0.06484039,-0.00014083528,-0.04217466,-0.07394988,0.027201263,-0.0022096422,-0.07401203,0.009320882,-0.0062965024,-0.0030855923,0.04623856,-0.02525424,-0.054521993,0.01548179,0.004777649,-0.01812168,-0.012616095,-0.004579919,-0.0075962013,0.02613615,0.038043354,0.023802254,0.04588446,-0.0053368737,-0.0034988362,-0.013993138,0.027221013,0.0359617,0.020805184,-0.00938742,-0.014166412,-0.08594609,0.013201592,0.028916374,-0.0023455794,-0.036008548,-0.017378122,-0.005484779,-0.053414512,-0.0110197,-0.053463507,0.0008750376,0.01283396,0.03570718,-0.034370225,0.017378543,0.03875626,-0.008704106,-0.00058240455,0.008425945,0.008887226,0.0042984504,-0.054705873,0.03424931,-0.008222518,0.029628128,0.0024422042,-0.013871515,0.044602036,0.0024356507,0.04276874,-0.0060988334,0.026193243,0.035553794,-0.013329511,-0.023663143,-0.02810813,-0.016106984,-0.018504946,-0.034949366,-0.05190229,-0.09996016,-0.014957739,0.0027282983,-0.011746966,0.027932491,-0.008406346,-0.0059022116,-0.0054451595,0.006064951,0.027290393,-0.052001916,0.024284469,-0.005183303,-0.00581681,0.03313836,-0.03686914,-0.0061032716,-0.02512159,-0.047975086,-0.012316617,0.06933903,0.0790455,-0.028899962,0.037315007,0.0029261864,-0.011576636,-0.013354656,-0.027511178,-0.030001596,-0.01258527,-0.059632905,0.015830167,-0.022935905,-0.0052615483,-0.031602815,0.034529,0.01370888,-0.0037114162,-0.026783854,0.020721897,-0.027785663,-0.07651694,-0.087816805,0.071910754,-0.03368178,-0.0042141085,0.0045980657,0.0619526,-0.010462813,-0.025336176,-0.061696995,0.02464066,-0.0322324,0.010361987,-0.011253096,-0.018709764,-0.015448008,-0.019254938,0.0031208894,-0.004342309,0.022065656,-0.02912145,0.042173866,-0.024126727,0.029209578,-0.00333524,-0.011441469,-0.02630411,-0.0021789183,0.06009351,0.09922027,0.015048585,-0.006998225,0.013689348,0.0010690683,0.011212169,0.014900842,-0.008159058,-0.049805675,-0.043109827,-0.03637891,-0.0022485342,0.042885933,-0.025394551,0.014408355,-0.036208525,0.008907432,-0.008181446,0.021813368,0.021916531,-0.00090585585,-0.011830238,0.015262092,0.031089043,-0.03636197,0.07452483,0.040354423,-0.0021877899,0.036888193,-0.011068082,-0.06748099,0.027310379,-0.015700161,-0.02426602,0.049452815,0.02391099,0.0055867354,-0.006786466,-0.03179285,-0.010792321,-0.0079312725,-0.052510694,-0.01426733,-0.013973344,0.035561483,-0.015138107,0.02965563,0.03519744,-0.016403763,-0.010580769,0.024784267,0.053801246,-0.011966856,0.009590207,0.008241026,-0.02135644,0.056017876,0.038430404,-0.0053951265,-0.0020605545,-0.015125702,-0.018464541,-0.06058644,0.04243049,-0.018915791,0.0055811703,0.081594266,0.009811076,0.006949532,0.018247921,0.007507183,0.0032894944,0.048993796,0.039932556,0.025504157,-0.095317006,0.022670647,-0.054650586,-0.0067043966,-0.015386722,0.016052173,-0.038170487,0.009542085,-0.0072341915,-0.020369591,0.04707151,-0.026664529,0.02484364,0.019020861,-0.003483344,0.030227125,-0.03293021,0.010213306,-0.03452474,0.03540027,0.009210933,0.00018540799,-0.017485095,-0.0067029535,-0.021646362,0.00806315,0.013469499,0.012342708,-0.0006427499,0.0036798038,-0.042963594,0.0010641247,-0.04045061,-0.036097668,-0.0027254168,0.0037026287,-0.031570733,-0.006166328,0.030460134,0.0044419616,0.010350618,-0.058804546,0.07920881,0.019756826,0.08330259,0.043526728,-0.07168001,-0.077368245,0.07571261,-0.017897412,-0.03606397,0.059067808,-0.017746609,0.007018881,0.018164068,-0.011165876,-0.13826886,-0.0525916,0.0098027475,0.007962661,-0.0052000214,-0.01496296,0.073450714,0.086982384,-0.042481527,-0.03283476,-0.0040138043,-0.05112667,0.02246716,-0.0249743,0.0524437,-0.066694506,-0.029796712,-0.03258697,-0.14519924,0.014601439,-0.05091772,-0.020718282,0.0066782315,-0.022530088,-0.019958977,-0.013986485,0.030909587,-0.008321195,0.026163822,0.018890226,-0.011387907,0.041874237,-0.0030468127,0.06306583,0.007593833,0.03606381,-0.044113856,0.01617283,-0.020421572,0.023665337,-0.00947067,0.00439739,-0.0018405052,0.0013197375,-0.03399253,-0.018495493,0.030057065,-0.029744942,0.0063731954,0.05300215,-0.05693633,0.015254497,-0.0051865256,-0.07453067,-0.08109584,-0.015111299,0.008216067,0.009552389,-0.031493492,0.014941514,-0.0014577003,0.008601964,0.04505451,0.027391152,0.032845844,-0.024230963,-0.006257476,-0.008288208,0.017263608,-0.004007801,0.03587647,0.018811384,-0.0023440942,-0.027592378,0.014788571,0.033195652,-0.012024712,-0.026094848,0.014704321,0.010908064,-0.040380057,0.076962076,-0.0042278524,0.06848525,-0.0018533313,-0.04876081,-0.03892265,-0.010046096,0.034804013,-0.0060935216,0.034957606,-0.02319653,-0.022998303,-0.039444465,-0.027011117,0.033828165,0.014994533,0.033979625,0.044618327,0.02658734,0.017191224,-0.011159709,0.008717765,0.049548116,-0.041621666,0.0025093497,-0.031359553,0.025314141,-0.032786123,0.044198506,-0.034303404,-0.016944868,0.028803926,0.015374457,-0.002420094,-0.044362072,0.014320643,-0.018716827,-0.005605615,0.0009709364,-0.0031795555,0.0065323105,0.001000608,0.015432782,-0.0541814,-0.01975336,0.025183206,0.00087034825,0.0077571087,0.076676145,0.021124898,0.039273135,0.011171002,0.0049340692,0.033406567,0.0062522464,-0.028874226,0.036194336,-0.028752396,0.025121342,-0.048206102,0.041936524,0.020699361,-0.02108163,0.02239294,-0.072067425,-0.020422714,-0.025838114,0.025833102,0.07068874,0.037831414,-0.011071826,-0.043451946,-0.057807636,-0.022806011,0.024615755,0.0016477623,-0.052537885,-0.06496491,-0.010409321,0.014129585,0.023101714,0.05957325,-0.010210365,-0.052850876,0.00087715214,0.07606739,-0.057984293,0.020242177,0.033746563,-5.4571658e-05,0.017523196,0.029120864,0.0019363024,-0.015217608,-0.00033506774,0.07949536,0.014871151,-0.05219692,0.039375864,0.015450847,-0.019535482,-0.0940066,-0.05361147,-0.040593248,0.045243945,-0.041029837,-0.007995695,-0.038586065,-0.037782878,0.0042549623,0.012025946,-0.02533831,-0.03682813,-0.00337695,-0.041925073,-0.0066307494,0.007523396,-0.0053186333,-0.021541018,0.03406503,-0.0188886,0.016275967,0.006445137,-0.061461516,0.04005594,0.020952096,-0.024915438,-0.046814308,-0.03451495,-0.00430798,0.018994547,0.038405135,0.024063637,0.0034121762,0.03742802,-0.021410186,0.0006959932,-0.027414111,-0.017597437,-0.0062092356,-0.00906407,-0.02953881,0.0108619295,0.019679278,0.0061574876,0.060124233,-0.012091719,-0.008250391,-0.020233363,-0.015811931,-0.031942558,0.0012951049,0.014756496,-0.024280038,-0.011290775,0.027864711,0.02677596,0.031994388,0.0056829727,0.041749205,-0.004897297,0.0038482985,0.014425885,0.0015871511,0.06510322,0.027252933,-0.003408669,-0.006411375,-0.019960742,-0.053113278,-0.006341974,0.00865483,-0.036882658,-0.010651091,-0.0057433294,-0.016185468,-0.020046325,0.02599982,0.018708533,-0.012137044,-0.0005042565,-0.008632624,0.009938957,0.0014667473,-0.02141617,0.04149996,0.07179281,-0.0150520345,0.01962518,0.030314263,0.0023516924,0.023399604,0.056364805,0.0017070009,0.021779958,-0.034458797,-0.0024679624,-0.0115883425,0.030196978,-0.025854915,-0.032455456,-0.0071550086,0.009765792,-0.036647927,-0.005174693,-0.013803105,0.018768702,-0.033734556,0.10232259,-0.056954395,0.0075420323,0.027821204,-0.044035032,0.041115902,0.008902332,0.010902019,-0.011199889,-0.010521268,0.030066531,0.035734363,0.040694673,0.06287629,0.018286113,0.00034794788,0.04018247,0.0061881486,-0.026144348,0.027252559,-0.04023897,-0.0037514034,-0.032701496,0.013437212,0.01661327,-0.01396825,-0.01848777,0.06366654,0.010386893,0.006525388,-0.01186112,-0.026132232]</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>2</td>\n",
              "            <td>연락처  <br>전력식  프로 <br>삼성SDS, 기술혁신팀  <br>rs.jeon @samsung.com   <br> <br>MariaDB/ MySQL 기술지원과   삼성그룹  주요 시스템  DBMS 성능개선을  담당하고  <br>있습니다 . <br> <br>박영철  프로 <br>삼성SDS, 기술혁신팀  <br>yngchul.park@samsung.com  <br> <br>Oracle DB, PostgreSQL , EPAS  기술지원을  담당하고  있으며 , 클라우드  기반 DB Service  <br>아키텍처 와 성능개선 에 관심이  있습니다 . <br> <br>민연홍  프로 <br>삼성SDS, 기술혁신팀  <br>yeonhong.min@samsung.com  <br> <br>Oracle Database 기술지원을  수행하였으며 , Oracle/SQL Server/SAP <br>HANA/Tibero/Redis Database 아키텍트  역할을  수행하고  있습니다 . DBMS on Cloud 에 <br>관심이  있습니다 . <br> <br>개정이력   <br>버전 변경 일자 변경 사항 <br>1.0 2023.7 최초 작성</td>\n",
              "            <td>{&#x27;page_label&#x27;: &#x27;2&#x27;, &#x27;file_name&#x27;: &#x27;/content/data/scp/scp_data.pdf&#x27;, &#x27;_node_content&#x27;: &#x27;{&quot;id_&quot;: &quot;84dd8a99-0238-4231-9110-b419386ff959&quot;, &quot;embedding&quot;: null, &quot;metadata&quot;: {&quot;page_label&quot;: &quot;2&quot;, &quot;file_name&quot;: &quot;/content/data/scp/scp_data.pdf&quot;}, &quot;excluded_embed_metadata_keys&quot;: [], &quot;excluded_llm_metadata_keys&quot;: [], &quot;relationships&quot;: {&quot;1&quot;: {&quot;node_id&quot;: &quot;22a68974-5935-437a-9b06-21da7d532e83&quot;, &quot;node_type&quot;: &quot;4&quot;, &quot;metadata&quot;: {&quot;page_label&quot;: &quot;2&quot;, &quot;file_name&quot;: &quot;/content/data/scp/scp_data.pdf&quot;}, &quot;hash&quot;: &quot;16f00e6d111bbca0edee05f74c510f0a71bc834d5c4ad1f8406606967a78f427&quot;, &quot;class_name&quot;: &quot;RelatedNodeInfo&quot;}, &quot;2&quot;: {&quot;node_id&quot;: &quot;3c267619-cafc-42d5-80ec-25b46b92fe04&quot;, &quot;node_type&quot;: &quot;1&quot;, &quot;metadata&quot;: {&quot;page_label&quot;: &quot;1&quot;, &quot;file_name&quot;: &quot;/content/data/scp/scp_data.pdf&quot;}, &quot;hash&quot;: &quot;36989b79fe5b266bc26277ff432d4b5e0b96a19e59e05908d20cb1ec5a2813ad&quot;, &quot;class_name&quot;: &quot;RelatedNodeInfo&quot;}, &quot;3&quot;: {&quot;node_id&quot;: &quot;f30cafbe-2849-4886-9ae5-6dab65e9d929&quot;, &quot;node_type&quot;: &quot;1&quot;, &quot;metadata&quot;: {}, &quot;hash&quot;: &quot;6050ff0d6857505f4841499a199f5e6f9125929044ec97841fea78e7c0514d5b&quot;, &quot;class_name&quot;: &quot;RelatedNodeInfo&quot;}}, &quot;text&quot;: &quot;&quot;, &quot;start_char_idx&quot;: 5, &quot;end_char_idx&quot;: 511, &quot;text_template&quot;: &quot;{metadata_str}\\\\n\\\\n{content}&quot;, &quot;metadata_template&quot;: &quot;{key}: {value}&quot;, &quot;metadata_seperator&quot;: &quot;\\\\n&quot;, &quot;class_name&quot;: &quot;TextNode&quot;}&#x27;, &#x27;_node_type&#x27;: &#x27;TextNode&#x27;, &#x27;document_id&#x27;: &#x27;22a68974-5935-437a-9b06-21da7d532e83&#x27;, &#x27;doc_id&#x27;: &#x27;22a68974-5935-437a-9b06-21da7d532e83&#x27;, &#x27;ref_doc_id&#x27;: &#x27;22a68974-5935-437a-9b06-21da7d532e83&#x27;}</td>\n",
              "            <td>84dd8a99-0238-4231-9110-b419386ff959</td>\n",
              "            <td>[-0.0011328842,-0.019668212,-0.0025737598,0.01949251,0.067293204,0.008884264,0.027260354,-0.0012221384,0.05180191,0.002421094,0.019379558,0.024641559,0.022026489,0.09352489,-0.0016308845,-0.056283753,0.03871588,-0.01594492,0.014111458,0.033391427,0.041589573,-0.004919571,0.059623923,-0.019100063,-0.07090117,-0.009269079,-0.019556187,0.011997195,-0.005202768,-0.011630618,0.00829536,0.04059918,0.022927888,0.039051488,0.0064419205,-0.033055257,0.0023966653,-0.009584857,-0.001166903,0.058065914,0.04339934,-0.06801316,-0.034070935,-0.016499829,-0.022087913,-0.051977243,-0.06032628,0.06110432,0.08451301,-0.02313947,0.014502086,0.028146567,-0.072044365,0.022354495,-0.003906281,-0.08408274,-0.000118781485,0.007874876,-0.0077019897,-0.011301247,0.025745861,-0.008352145,-0.013162065,-0.014149109,0.02081658,-0.024430636,-0.047748435,0.013823367,0.006061165,-0.010825623,0.17725886,0.03586692,-0.019377265,-0.022736676,-0.0055602747,-0.008922952,0.010089582,-0.027832972,0.011546691,-0.019731369,0.01859366,-0.016615216,-0.027914334,-0.0654807,-0.022586526,0.041124765,-0.0018824479,0.016730988,-0.009705437,0.02649973,0.025327701,-0.035034586,-0.025022253,-0.034850985,-0.014574008,0.03790008,0.016655874,-0.09027622,-0.0025432173,-0.0012843395,0.06702021,0.010844035,0.023747299,0.027521381,0.03223245,0.029828886,0.035289787,0.0074618277,0.028957745,0.003966314,0.06651541,-0.014769864,-0.010657483,0.015628004,-0.005315049,-0.03201105,0.00083041063,0.040072378,-0.041206874,0.022705315,0.17882441,-0.02337447,0.0055443095,0.011366597,0.00429469,0.01777205,0.03801449,0.026193833,0.0030436544,0.008731393,-0.006544053,-0.024475124,0.010712896,0.026156044,0.028005693,0.015759699,0.016633147,-0.03773023,-0.13744725,-0.030319419,-0.0060244068,-0.021565164,-0.064108096,0.030025981,-0.002918985,0.00959868,-0.024051646,0.055645194,-0.005888841,0.022302944,-0.016215585,0.017398743,-0.038163688,0.01594776,-0.026962562,-0.0056830947,-0.07068215,0.011517432,-0.0715928,-0.007817845,-0.015145043,0.010127085,-0.05653725,0.034256462,-0.02543016,0.06274114,0.0025776955,-0.020992737,0.05662386,-0.058001935,-0.018810986,0.008827772,0.02843722,0.07344351,0.029820971,0.01925281,0.057152424,-0.039839737,-0.022980511,0.016100202,-0.028792439,-0.07910602,0.05467791,0.016111804,-0.023255628,0.0377175,-0.06161061,-0.033385195,-0.0010924502,0.014897229,-0.016187979,-0.0013531402,-0.022848872,0.015737316,0.04079611,0.029073782,-0.01879393,0.02856021,-6.336965e-05,0.0048010605,-0.0033393826,0.004575673,-0.038140006,0.05164037,0.013736619,-0.033467676,-0.046033517,0.023083758,-0.047854975,0.0042230505,0.041298486,-0.0021751574,-0.014079619,-0.0063456027,-0.00072963245,-0.0391077,0.024700973,-0.0026450779,-0.0033174865,-0.0022402995,-0.0018599497,0.062520206,0.0060358346,0.012564966,0.040982746,0.017000943,0.0332484,-0.031675518,0.020944104,0.0026617313,0.0338699,0.012416159,-0.0032310484,0.041235972,0.016241321,0.062370487,0.054579355,0.03490009,0.008835583,0.0050261747,-0.0045577064,0.0053142966,-0.035212997,-0.022036443,-0.020048885,-0.07285713,-0.07999449,-0.0113846315,0.020756984,-0.010850307,0.0067642434,-0.018952003,-0.009658002,0.020177064,0.041132342,0.0652971,-0.07691203,0.032698136,0.0058704293,-0.0032439423,0.040108204,-0.03540728,-0.033320986,-0.010724459,-0.008061478,-0.034633722,-0.000770488,-0.018351914,-0.021423226,0.050426137,0.025615351,0.009989611,-0.01724193,-0.009980531,-0.0059157168,-0.0006349613,-0.06032492,0.03356381,-0.011004069,0.01508903,-0.0023403368,0.023845548,0.014251546,0.0007695542,-0.032642383,0.006703468,0.03070835,-0.057663508,-0.079452015,0.055853058,0.010066699,-0.0020700265,0.030334918,0.007998856,-0.014460742,-0.03404181,-0.0383967,0.0553396,-0.010991793,0.024221368,0.008828926,-0.035442367,-0.0022646813,-0.01805184,-0.00597564,0.036452107,0.02719978,-0.033805117,0.04541595,-0.024493461,0.04880328,-0.015975948,0.008339648,0.0063855825,-0.0012642982,0.041915584,0.09148457,-0.004593453,0.0097520845,0.039615635,0.0037775151,0.015758628,0.012708412,-0.009847431,-0.04760129,-0.07262222,-0.023381809,-0.029097207,0.027928332,-0.040674914,-0.0009959799,-0.07491581,-0.002323792,0.009122427,0.044875763,0.023151724,-0.009924383,-0.013506893,0.012935554,0.021957241,-0.04966379,0.030259477,0.035583183,0.046944518,0.025000034,-0.004811199,-0.0037025257,0.04359492,0.007238152,-0.015464798,0.021309085,0.032442655,0.013412672,-0.037293658,-0.012488596,-0.047250018,-0.00029336283,-0.044129744,-0.041900445,-0.016223013,0.038226426,-0.031218527,0.021850012,0.011605532,-0.035074946,-0.0040870393,0.01985566,0.0125276325,0.00037354906,-0.015159453,0.00012708378,-0.057989337,0.03419229,0.028156625,0.0162804,-0.002149355,-0.00045324085,-0.016843315,-0.104155056,0.042504642,0.010492797,0.035743244,0.092035614,-0.0042847646,0.006636167,-0.009806072,0.019456398,-0.018260146,0.026490126,0.044648413,0.009499332,-0.08979663,0.01013671,-0.048570488,0.020966932,-0.019784963,-0.0032414675,-0.013336541,0.0082637295,-0.006631805,-0.033900525,0.042287495,-0.033915803,0.0022558842,0.008667488,-0.02957593,0.033928543,-0.0004313,0.011041733,-0.04628749,0.06022223,-0.021329513,-0.018473595,-0.03170299,-0.0069881314,-0.029524796,-0.023952983,-0.018195854,-0.006691463,-0.03446109,0.0653658,-0.020161064,0.01811052,-0.010900329,-0.04699988,-0.019969666,0.051164735,-0.0011078591,0.0134063,0.013372391,-0.0066007865,-0.017615438,-0.05456612,0.06620533,0.050759126,0.046014972,0.0562578,-0.026699524,-0.05791005,0.057458233,-0.02834368,-0.02119205,0.09614895,0.0037414336,0.03196817,0.022663763,0.005669699,-0.08409024,-0.075048804,0.045800056,0.031012716,0.028121252,-0.009059692,0.04701706,0.0988406,-0.04378528,-0.09310738,-0.032186653,-0.04273633,-0.00046898134,-0.041801464,0.08939686,-0.053672723,-0.027553977,-0.038019303,-0.19816239,0.05223058,-0.08930818,-0.002178004,-0.008997163,-0.02794872,-0.014997449,-0.017380102,0.051988512,0.013408921,0.006194614,0.002453914,-0.014905484,-0.014683927,-0.00671591,0.095801696,0.0067246906,0.03127099,-0.097756654,0.0061601596,-0.027752563,-0.00039225575,0.008502024,0.018973943,-0.04144525,-0.007600707,-0.026170723,-5.12919e-05,0.06817032,-0.0060613872,-0.045390785,0.08013956,-0.017179862,-0.025852,0.018050862,-0.07814751,-0.049268223,0.028619055,-0.07464153,0.02488957,-0.022572739,-0.0051420894,-0.016487723,0.0041389004,0.012663008,0.02387898,0.017735103,-0.01559523,-0.038943764,-0.0057197586,-0.0311011,0.005707166,0.05278073,0.032258052,0.0038263772,-0.021824358,0.0071264184,0.028874295,0.017236955,-0.006627574,0.015836358,0.008978065,-0.031879485,0.03986133,0.013368403,0.041714743,-0.025336416,-0.033801656,-0.04571222,-0.0026224616,0.00078710495,0.014645492,0.06324591,-0.045126364,-0.01429014,-0.035506867,0.015943686,-0.034070946,0.024610816,0.041418042,0.040040392,0.006707241,0.01626368,-0.011129985,0.02191148,0.026708687,-0.061619643,-0.011832902,-0.016892117,0.05224211,-0.03252159,0.026047202,-0.039741244,-0.020346696,0.0548293,-0.0047395104,-0.006584244,-0.030202562,0.013514642,-0.056073926,-0.014246019,0.009150209,-0.00599886,0.007745739,-0.015406701,0.054166943,-0.040118646,-0.0016118281,0.058527924,-0.0004069424,0.013202471,0.029692348,0.020142555,0.043712728,-0.016412145,0.012668814,0.05179209,-0.00044064948,0.0019323746,0.030276874,-0.03205683,0.028082905,-0.0069899843,0.014289441,0.008390541,-0.014793417,0.052310556,-0.056912195,-0.04522228,-0.022191988,0.020886397,0.04600385,0.044979617,0.04570337,-0.008927223,-0.0363776,-0.04183252,0.018487493,0.01327941,-0.02347609,-0.0355081,-0.032167893,0.0027344264,0.015473616,0.08080141,0.01749087,-0.07205922,-0.00825824,0.0670911,-0.020286774,9.2062095e-05,-0.00048471199,0.016949415,0.013003237,0.028672827,-0.035684336,-0.024497496,-0.03374388,0.09064786,0.04108633,-0.026561886,0.06936252,0.00055976823,-0.0038677687,-0.09482903,-0.048337463,-0.048502855,0.011415448,-0.028923621,-0.0034419384,-0.010094307,-0.023772039,-0.013932039,-0.0017384702,-0.0061991764,-0.03804246,0.0052145342,-0.08127817,-0.029870126,0.0018627372,-0.0019917672,-0.011643835,0.019066839,-0.031400625,-0.0047745095,0.0042267013,-0.03273181,0.0031581682,-0.010539616,-0.027905205,-0.031168375,-0.02696279,0.004519456,-0.0016401326,0.07895292,0.018358495,0.016972251,-0.0017875533,-0.037745845,-0.016159508,-0.0061714035,-0.024067659,0.017331934,-0.0023918871,-0.062657125,0.005802609,0.030300867,0.014477998,0.0529159,0.006205926,-0.0019798896,-0.0379135,-0.030062763,0.0035816778,0.0029673337,0.021316627,-0.033282574,-0.002482629,-0.008207335,0.014449144,0.001487758,0.010578932,0.01883429,0.0012256398,0.003251289,0.041964132,-0.004279066,0.08692933,0.030048732,0.0039984575,0.013825631,-0.029905295,-0.040205464,0.010120376,0.01442786,-0.043106385,-0.025133891,0.014135656,-0.0027896978,-0.043500163,0.0067104427,-0.017369742,-0.0398807,0.030135477,-0.001726513,0.020048821,0.010720824,-0.041028224,0.02442659,0.05357134,0.0050559207,0.004483531,0.04305425,0.023514414,0.030645872,0.07128646,0.008973136,0.060711607,-0.02143632,-0.03602115,-0.049110726,0.017525269,-0.013353099,0.0109703075,0.023102479,-0.007366484,-0.022146277,-0.0056540133,0.02210034,-0.009877439,-0.025352972,0.06771294,-0.018666785,-0.034557868,0.01305576,-0.044895887,0.027142404,0.020115053,0.000351456,-0.0036920765,-0.015185139,0.056937702,0.024779763,0.043110102,0.023034088,-0.0025212637,0.004420197,0.020629004,0.02726968,0.023161083,0.007921157,-0.06878212,0.0060886513,-0.020720128,0.014157996,-0.012962663,-0.020051938,-0.018600719,-0.07629737,0.019677155,0.019214407,-0.014087414,-0.020143084]</td>\n",
              "        </tr>\n",
              "    </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "CREATE INDEX ON data_text_embedding\n",
        "USING ivfflat (embedding vector_cosine_ops)\n",
        "WITH (lists = 20);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KR2qndLZoJlS",
        "outputId": "633da0ad-193f-4f23-bed9-2c9465ef4c29"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * postgresql://postgres:***@localhost:5432/vector_db\n",
            "Done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrival"
      ],
      "metadata": {
        "id": "bAmLa-RxoyLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.retrievers import VectorIndexRetriever\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "from llama_index.core.indices.postprocessor import SimilarityPostprocessor\n",
        "\n",
        "TOP_K = 3\n",
        "SIMILARITY_CUTOFF = 0.3\n",
        "\n",
        "retriever = VectorIndexRetriever(\n",
        "    index=index,\n",
        "    similarity_top_k=TOP_K,\n",
        ")\n",
        "\n",
        "query_engine = RetrieverQueryEngine(\n",
        "    retriever=retriever,\n",
        "    node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=SIMILARITY_CUTOFF)],\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "vpG8zqr_oqgu"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt Engineering"
      ],
      "metadata": {
        "id": "BOvoD9uDtONa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import PromptTemplate\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "def display_prompt_dict(prompts_dict):\n",
        "    for key, value in prompts_dict.items():\n",
        "        text_md = f\"**Prompt Key**: **{key}**<br>\" f\"**Text:** <br>\"\n",
        "        display(Markdown(text_md))\n",
        "        print(value.get_template())\n",
        "        display(Markdown((\"<br><br>\")))\n",
        "        #display(Markdown(f\"**{key}**\"))\n",
        "        #display(Markdown(value))"
      ],
      "metadata": {
        "id": "4wBFfuwKrfZy"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_prompt_tmpl_str = \"\"\"\\\n",
        "We have provided context information below.\n",
        "---------------------\n",
        "{context_str}\n",
        "---------------------\n",
        "Given this information, please answer the question: {query_str}\n",
        "Answer: \\\n",
        "\"\"\"\n",
        "qa_prompt_tmpl = PromptTemplate(\n",
        "    qa_prompt_tmpl_str,\n",
        ")"
      ],
      "metadata": {
        "id": "Qkk-xaZuu_Oh"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine.update_prompts(\n",
        "    {\"response_synthesizer:text_qa_template\": qa_prompt_tmpl}\n",
        ")"
      ],
      "metadata": {
        "id": "FbOhSAUbv8HS"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_prompt_dict(query_engine.get_prompts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "dTRFo-0YwFG9",
        "outputId": "d9ef8c24-d5d1-4ef8-8a13-e73f7202ac89"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Prompt Key**: **response_synthesizer:text_qa_template**<br>**Text:** <br>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have provided context information below.\n",
            "---------------------\n",
            "{context_str}\n",
            "---------------------\n",
            "Given this information, please answer the question: {query_str}\n",
            "Answer: \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<br><br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Prompt Key**: **response_synthesizer:refine_template**<br>**Text:** <br>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The original query is as follows: {query_str}\n",
            "We have provided an existing answer: {existing_answer}\n",
            "We have the opportunity to refine the existing answer (only if needed) with some more context below.\n",
            "------------\n",
            "{context_msg}\n",
            "------------\n",
            "Given the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\n",
            "Refined Answer: \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<br><br>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question and Answering"
      ],
      "metadata": {
        "id": "MfU-wIjXwqlB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_query = \"What is the scp backup?\""
      ],
      "metadata": {
        "id": "pVwrr9MBwJd0"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Query\n",
        "print(query_engine.query(user_query))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "zP7LRX8UxCF1",
        "outputId": "580b0d2e-ad64-4720-8837-a5c157889b11"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-122-b20bb56d5a1a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/base/base_query_engine.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_or_query_bundle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mstr_or_query_bundle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQueryBundle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_or_query_bundle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_or_query_bundle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr_or_query_bundle\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mQueryType\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mRESPONSE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/query_engine/retriever_query_engine.py\u001b[0m in \u001b[0;36m_query\u001b[0;34m(self, query_bundle)\u001b[0m\n\u001b[1;32m    185\u001b[0m         ) as query_event:\n\u001b[1;32m    186\u001b[0m             \u001b[0mnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_bundle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             response = self._response_synthesizer.synthesize(\n\u001b[0m\u001b[1;32m    188\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_bundle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0mnodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/response_synthesizers/base.py\u001b[0m in \u001b[0;36msynthesize\u001b[0;34m(self, query, nodes, additional_source_nodes, **response_kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mCBEventType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSYNTHESIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpayload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mEventPayload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQUERY_STR\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_str\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         ) as event:\n\u001b[0;32m--> 206\u001b[0;31m             response_str = self.get_response(\n\u001b[0m\u001b[1;32m    207\u001b[0m                 \u001b[0mquery_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_str\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                 text_chunks=[\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/response_synthesizers/compact_and_refine.py\u001b[0m in \u001b[0;36mget_response\u001b[0;34m(self, query_str, text_chunks, prev_response, **response_kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# the refine template does not account for size of previous answer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mnew_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_compact_text_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_chunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         return super().get_response(\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mquery_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_str\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mtext_chunks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_texts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/response_synthesizers/refine.py\u001b[0m in \u001b[0;36mget_response\u001b[0;34m(self, query_str, text_chunks, prev_response, **response_kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;31m# if this is the first chunk, and text chunk already\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;31m# is an answer, then return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                 response = self._give_response_single(\n\u001b[0m\u001b[1;32m    173\u001b[0m                     \u001b[0mquery_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mresponse_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/response_synthesizers/refine.py\u001b[0m in \u001b[0;36m_give_response_single\u001b[0;34m(self, query_str, text_chunk, **response_kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m                     structured_response = cast(\n\u001b[1;32m    225\u001b[0m                         \u001b[0mStructuredRefineResponse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m                         program(\n\u001b[0m\u001b[1;32m    227\u001b[0m                             \u001b[0mcontext_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_text_chunk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m                             \u001b[0;34m**\u001b[0m\u001b[0mresponse_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/response_synthesizers/refine.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             answer = self._llm.predict(\n\u001b[0m\u001b[1;32m     78\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/llms/llm.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, prompt, **prompt_args)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0mformatted_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mprompt_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformatted_prompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/llms/callbacks.py\u001b[0m in \u001b[0;36mwrapped_llm_predict\u001b[0;34m(_self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 )\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mf_return_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_return_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;31m# intercept the generator and add a callback to the end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/llms/llama_cpp/base.py\u001b[0m in \u001b[0;36mcomplete\u001b[0;34m(self, prompt, formatted, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompletion_to_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mCompletionResponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"choices\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_cpp/llama.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[0m\n\u001b[1;32m   1539\u001b[0m             \u001b[0mResponse\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgenerated\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m         \"\"\"\n\u001b[0;32m-> 1541\u001b[0;31m         return self.create_completion(\n\u001b[0m\u001b[1;32m   1542\u001b[0m             \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m             \u001b[0msuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_cpp/llama.py\u001b[0m in \u001b[0;36mcreate_completion\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[0m\n\u001b[1;32m   1472\u001b[0m             \u001b[0mchunks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCreateCompletionStreamResponse\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompletion_or_chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1474\u001b[0;31m         \u001b[0mcompletion\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCompletion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompletion_or_chunks\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcompletion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_cpp/llama.py\u001b[0m in \u001b[0;36m_create_completion\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[0m\n\u001b[1;32m    998\u001b[0m         \u001b[0mfinish_reason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"length\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m         \u001b[0mmultibyte_fix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1000\u001b[0;31m         for token in self.generate(\n\u001b[0m\u001b[1;32m   1001\u001b[0m             \u001b[0mprompt_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m             \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_cpp/llama.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, tokens, top_k, top_p, min_p, typical_p, temp, repeat_penalty, reset, frequency_penalty, presence_penalty, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, penalize_nl, logits_processor, stopping_criteria, grammar)\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;31m# Eval and sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msample_idx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_tokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m                 token = self.sample(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_cpp/llama.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_past\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits_all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             )\n\u001b[0;32m--> 522\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0;31m# Save tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_past\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mn_past\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn_tokens\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_cpp/_internals.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         return_code = llama_cpp.llama_decode(\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_query = \"SCP Database는 몇종이고, 어떤 DB가 있나요?\""
      ],
      "metadata": {
        "id": "6LIl1VtQxI2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Query\n",
        "print(query_engine.query(user_query))"
      ],
      "metadata": {
        "id": "K67Xd1EExsUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uN5BTHLexy-K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}