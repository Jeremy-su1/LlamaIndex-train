{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jeremy-su1/LlamaIndex-train/blob/main/Copy_of_WebPageDemo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30146ad2-f165-4f4b-ae07-fe6597a2964f",
      "metadata": {
        "id": "30146ad2-f165-4f4b-ae07-fe6597a2964f"
      },
      "source": [
        "# Web Page Reader\n",
        "\n",
        "Demonstrates our web page reader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f9959b5",
      "metadata": {
        "id": "9f9959b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dcf0b37-aa0e-4efe-a020-f7b59f7023c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index-readers-web\n",
            "  Downloading llama_index_readers_web-0.1.7-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m760.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-web) (3.9.3)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-web) (4.12.3)\n",
            "Collecting chromedriver-autoinstaller<0.7.0,>=0.6.3 (from llama-index-readers-web)\n",
            "  Downloading chromedriver_autoinstaller-0.6.4-py3-none-any.whl (7.6 kB)\n",
            "Collecting html2text<2021.0.0,>=2020.1.16 (from llama-index-readers-web)\n",
            "  Downloading html2text-2020.1.16-py3-none-any.whl (32 kB)\n",
            "Collecting llama-index-core<0.11.0,>=0.10.1 (from llama-index-readers-web)\n",
            "  Downloading llama_index_core-0.10.20.post2-py3-none-any.whl (15.4 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting newspaper3k<0.3.0,>=0.2.8 (from llama-index-readers-web)\n",
            "  Downloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.1/211.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting playwright<2.0,>=1.30 (from llama-index-readers-web)\n",
            "  Downloading playwright-1.42.0-py3-none-manylinux1_x86_64.whl (37.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-web) (2.31.0)\n",
            "Collecting selenium<5.0.0,>=4.17.2 (from llama-index-readers-web)\n",
            "  Downloading selenium-4.18.1-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-web) (2.0.7)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web) (4.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-web) (2.5)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from chromedriver-autoinstaller<0.7.0,>=0.6.3->llama-index-readers-web) (24.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web) (2.0.28)\n",
            "Collecting dataclasses-json (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web) (2023.6.0)\n",
            "Collecting httpx (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llamaindex-py-client<0.2.0,>=0.1.13 (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web)\n",
            "  Downloading llamaindex_py_client-0.1.13-py3-none-any.whl (107 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web) (3.2.1)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web) (1.25.2)\n",
            "Collecting openai>=1.1.0 (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web)\n",
            "  Downloading openai-1.14.1-py3-none-any.whl (257 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m257.5/257.5 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web) (1.5.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web) (9.4.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web) (8.2.3)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web) (4.10.0)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting cssselect>=0.9.2 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web)\n",
            "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web) (4.9.4)\n",
            "Collecting feedparser>=5.2.1 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web)\n",
            "  Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tldextract>=2.0.1 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web)\n",
            "  Downloading tldextract-5.1.1-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m97.7/97.7 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting feedfinder2>=0.0.4 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web)\n",
            "  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jieba3k>=0.35.1 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web)\n",
            "  Downloading jieba3k-0.35.1.zip (7.4 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web) (2.8.2)\n",
            "Collecting tinysegmenter==0.3 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web)\n",
            "  Downloading tinysegmenter-0.3.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: greenlet==3.0.3 in /usr/local/lib/python3.10/dist-packages (from playwright<2.0,>=1.30->llama-index-readers-web) (3.0.3)\n",
            "Collecting pyee==11.0.1 (from playwright<2.0,>=1.30->llama-index-readers-web)\n",
            "  Downloading pyee-11.0.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->llama-index-readers-web) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->llama-index-readers-web) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->llama-index-readers-web) (2024.2.2)\n",
            "Collecting trio~=0.17 (from selenium<5.0.0,>=4.17.2->llama-index-readers-web)\n",
            "  Downloading trio-0.25.0-py3-none-any.whl (467 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m467.2/467.2 kB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trio-websocket~=0.9 (from selenium<5.0.0,>=4.17.2->llama-index-readers-web)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web) (1.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from feedfinder2>=0.0.4->newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web) (1.16.0)\n",
            "Collecting sgmllib3k (from feedparser>=5.2.1->newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web) (2.6.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web) (3.7.1)\n",
            "Collecting httpcore==1.* (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web) (2023.12.25)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web) (1.7.0)\n",
            "Collecting requests-file>=1.4 (from tldextract>=2.0.1->newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web)\n",
            "  Downloading requests_file-2.0.0-py2.py3-none-any.whl (4.2 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from tldextract>=2.0.1->newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web) (3.13.1)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium<5.0.0,>=4.17.2->llama-index-readers-web) (2.4.0)\n",
            "Collecting outcome (from trio~=0.17->selenium<5.0.0,>=4.17.2->llama-index-readers-web)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium<5.0.0,>=4.17.2->llama-index-readers-web) (1.2.0)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium<5.0.0,>=4.17.2->llama-index-readers-web)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3>=1.1.0->llama-index-readers-web) (1.7.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web) (2023.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web) (2.16.3)\n",
            "Building wheels for collected packages: tinysegmenter, feedfinder2, jieba3k, sgmllib3k\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13538 sha256=2fd609693fd45b6a57d5731d594bd321ba39555dcda161b213b1d47e68a5fe29\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/d6/6c/384f58df48c00b9a31d638005143b5b3ac62c3d25fb1447f23\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3340 sha256=e9749b102b737375d1fc31524ff80b232ccccc6e18551dd59021ea138be7e482\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/02/e7/a1ff1760e12bdbaab0ac824fae5c1bc933e41c4ccd6a8f8edb\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398382 sha256=8676b49249d2d2abaa611d02f946fdd7a352320817d62327084f54481359e7f3\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/c4/0c/12a9a314ecac499456c4c3b2fcc2f635a3b45a39dfbd240299\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6049 sha256=651cfffc0550f76c743dcc83110dcf57a1bdd213cda7682a4893174419054cf8\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/69/93/a47e9d621be168e9e33c7ce60524393c0b92ae83cf6c6e89c5\n",
            "Successfully built tinysegmenter feedfinder2 jieba3k sgmllib3k\n",
            "Installing collected packages: tinysegmenter, sgmllib3k, jieba3k, dirtyjson, pyee, outcome, mypy-extensions, marshmallow, html2text, h11, feedparser, deprecated, cssselect, chromedriver-autoinstaller, wsproto, typing-inspect, trio, tiktoken, requests-file, playwright, httpcore, feedfinder2, trio-websocket, tldextract, httpx, dataclasses-json, selenium, openai, newspaper3k, llamaindex-py-client, llama-index-core, llama-index-readers-web\n",
            "Successfully installed chromedriver-autoinstaller-0.6.4 cssselect-1.2.0 dataclasses-json-0.6.4 deprecated-1.2.14 dirtyjson-1.0.8 feedfinder2-0.0.4 feedparser-6.0.11 h11-0.14.0 html2text-2020.1.16 httpcore-1.0.4 httpx-0.27.0 jieba3k-0.35.1 llama-index-core-0.10.20.post2 llama-index-readers-web-0.1.7 llamaindex-py-client-0.1.13 marshmallow-3.21.1 mypy-extensions-1.0.0 newspaper3k-0.2.8 openai-1.14.1 outcome-1.3.0.post0 playwright-1.42.0 pyee-11.0.1 requests-file-2.0.0 selenium-4.18.1 sgmllib3k-1.0.0 tiktoken-0.6.0 tinysegmenter-0.3 tldextract-5.1.1 trio-0.25.0 trio-websocket-0.11.1 typing-inspect-0.9.0 wsproto-1.2.0\n"
          ]
        }
      ],
      "source": [
        "%pip install llama-index-readers-web"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c39063b",
      "metadata": {
        "id": "3c39063b"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import sys\n",
        "\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
        "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2315a154-f72d-4447-b1eb-cde9b66868cb",
      "metadata": {
        "id": "2315a154-f72d-4447-b1eb-cde9b66868cb"
      },
      "source": [
        "#### Using SimpleWebPageReader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bed9032b",
      "metadata": {
        "id": "bed9032b"
      },
      "source": [
        "If you're opening this Notebook on colab, you will probably need to install LlamaIndex ğŸ¦™."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76a5165b",
      "metadata": {
        "id": "76a5165b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8de66cb3-be59-45e6-b3a1-a1a3767d8809"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index\n",
            "  Downloading llama_index-0.10.20-py3-none-any.whl (5.6 kB)\n",
            "Collecting llama-index-agent-openai<0.2.0,>=0.1.4 (from llama-index)\n",
            "  Downloading llama_index_agent_openai-0.1.5-py3-none-any.whl (12 kB)\n",
            "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index)\n",
            "  Downloading llama_index_cli-0.1.9-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.20 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.10.20.post2)\n",
            "Collecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index)\n",
            "  Downloading llama_index_embeddings_openai-0.1.6-py3-none-any.whl (6.0 kB)\n",
            "Collecting llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 (from llama-index)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.1.4-py3-none-any.whl (6.6 kB)\n",
            "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n",
            "  Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-llms-openai<0.2.0,>=0.1.5 (from llama-index)\n",
            "  Downloading llama_index_llms_openai-0.1.12-py3-none-any.whl (10 kB)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.1.4-py3-none-any.whl (5.8 kB)\n",
            "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index)\n",
            "  Downloading llama_index_program_openai-0.1.4-py3-none-any.whl (4.1 kB)\n",
            "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index)\n",
            "  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
            "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index)\n",
            "  Downloading llama_index_readers_file-0.1.11-py3-none-any.whl (36 kB)\n",
            "Collecting llama-index-readers-llama-parse<0.2.0,>=0.1.2 (from llama-index)\n",
            "  Downloading llama_index_readers_llama_parse-0.1.3-py3-none-any.whl (2.5 kB)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (3.9.3)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (0.6.4)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (2023.6.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (0.27.0)\n",
            "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.13 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (0.1.13)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (3.2.1)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (1.25.2)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (1.14.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (1.5.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (8.2.3)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (4.10.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index) (0.9.0)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\n",
            "Collecting bs4<0.0.3,>=0.0.2 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Collecting pymupdf<2.0.0,>=1.23.21 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
            "  Downloading PyMuPDF-1.23.26-cp310-none-manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
            "  Downloading pypdf-4.1.0-py3-none-any.whl (286 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m286.1/286.1 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Collecting llama-parse<0.4.0,>=0.3.3 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index)\n",
            "  Downloading llama_parse-0.3.9-py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.20->llama-index) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.20->llama-index) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.20->llama-index) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.20->llama-index) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.20->llama-index) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.20->llama-index) (4.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.20->llama-index) (1.14.1)\n",
            "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.20->llama-index) (2.6.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.20->llama-index) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.20->llama-index) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.20->llama-index) (1.0.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.20->llama-index) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.20->llama-index) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.20->llama-index) (0.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.20->llama-index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.20->llama-index) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.20->llama-index) (2023.12.25)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.20->llama-index) (1.7.0)\n",
            "Collecting PyMuPDFb==1.23.22 (from pymupdf<2.0.0,>=1.23.21->llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
            "  Downloading PyMuPDFb-1.23.22-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.6 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.20->llama-index) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.20->llama-index) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.20->llama-index) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.20->llama-index) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.20->llama-index) (3.21.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.20->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.20->llama-index) (2023.4)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.20->llama-index) (1.2.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.20->llama-index) (24.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.20->llama-index) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.20->llama-index) (2.16.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->llama-index-core<0.11.0,>=0.10.20->llama-index) (1.16.0)\n",
            "Installing collected packages: striprtf, pypdf, PyMuPDFb, pymupdf, bs4, llama-index-legacy, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
            "Successfully installed PyMuPDFb-1.23.22 bs4-0.0.2 llama-index-0.10.20 llama-index-agent-openai-0.1.5 llama-index-cli-0.1.9 llama-index-embeddings-openai-0.1.6 llama-index-indices-managed-llama-cloud-0.1.4 llama-index-legacy-0.9.48 llama-index-llms-openai-0.1.12 llama-index-multi-modal-llms-openai-0.1.4 llama-index-program-openai-0.1.4 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.11 llama-index-readers-llama-parse-0.1.3 llama-parse-0.3.9 pymupdf-1.23.26 pypdf-4.1.0 striprtf-0.0.26\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87bf7ecd-50cd-47da-9f0e-bc48d7ae45d8",
      "metadata": {
        "id": "87bf7ecd-50cd-47da-9f0e-bc48d7ae45d8"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import SummaryIndex\n",
        "from llama_index.readers.web import SimpleWebPageReader\n",
        "from IPython.display import Markdown, display\n",
        "import os\n",
        "from llama_index.core import VectorStoreIndex"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# openai api key ì‚¬ìš©ì‹œì— ìˆ˜í–‰\n",
        "import os\n",
        "import openai\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"Your openai API key\"\n",
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
      ],
      "metadata": {
        "id": "HWlXEqSxHjE_"
      },
      "id": "HWlXEqSxHjE_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6de3929-51eb-4064-b4b6-c203bb6debc4",
      "metadata": {
        "id": "b6de3929-51eb-4064-b4b6-c203bb6debc4"
      },
      "outputs": [],
      "source": [
        "# NOTE: the html_to_text=True option requires html2text to be installed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "663403de-2e6e-4340-ab8f-8ee681bc06aa",
      "metadata": {
        "id": "663403de-2e6e-4340-ab8f-8ee681bc06aa"
      },
      "outputs": [],
      "source": [
        "documents = SimpleWebPageReader(html_to_text=True).load_data(\n",
        "    [\"https://www.datastax.com/ko/guides/what-is-llamaindex\",\n",
        "     \"https://docs.llamaindex.ai/en/latest/index.html\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8cd183a-2423-4a3e-ad92-dfe89ed5454e",
      "metadata": {
        "id": "b8cd183a-2423-4a3e-ad92-dfe89ed5454e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9ae59bb-7f86-4b85-8463-94b68f1a578e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(id_='https://www.datastax.com/ko/guides/what-is-llamaindex', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='[](/ko \"DataStax\")\\n\\n  * Products\\n  * [Pricing](/ko/pricing)\\n  * Stories\\n  * Resources\\n\\n  * [Docs](https://docs.datastax.com/en/astra/astra-db-vector/index.html)\\n  * [Contact Us](/ko/contact-us)\\n  * [Sign In](https://astra.datastax.com/)\\n\\n  * [Sign In](https://astra.datastax.com/)\\n  * [Try For Free](https://astra.datastax.com/signup?utm_source=website)\\n\\n[Back to Resources](/ko/resources)\\n\\nGuide â€¢ Nov 01, 2023\\n\\n# What is LlamaIndex? Exploring the World of LLM Orchestration Frameworks\\n\\n **LlamaIndex provides a complete set of tools for preparing and querying data\\nfor LLMs, including RAG. How does this streamline the data preparation process\\nfor AI models?**\\n\\n[ Sign Up for\\nAstra](https://astra.datastax.com/register?utm_source=llamaindex_guide&utm_medium=guide&utm_campaign=guidepillar)\\n\\n![Bill\\nMcLane](https://cdn.sanity.io/images/bbnkhnhl/production/2a2b00d8851ca108c9f05bc167806a47a26b8e2a-3050x2295.jpg?w=96&q=75&fit=clip&auto=format)\\n\\n###### Bill McLane\\n\\n###### CTO Cloud\\n\\n![](https://cdn.sanity.io/images/bbnkhnhl/production/d75fd5143b6647e8b658dec590ee501d0e56d455-672x672.png?w=1920&q=75&fit=clip&auto=format)\\n\\n## What is LlamaIndex?\\n\\n**LlamaIndex is an orchestration framework that simplifies the integration of\\nprivate data with public data for building applications using Large Language\\nModels (LLMs). It provides tools for data ingestion, indexing, and querying,\\nmaking it a versatile solution for generative AI needs.**\\n\\nWith the rapid integration of [generative\\nAI](https://www.datastax.com/guides/what-is-generative-ai) into the\\napplication development process we are seeing an increasing need to be able to\\nintegrate our own private data with public data that is being used to train\\nl[arge language models](https://www.datastax.com/guides/what-is-a-large-\\nlanguage-model) (LLMs). The challenge this presents is that most private data\\nis unstructured, siloed, and not in a format that can be readily accessible by\\nLLMs.\\n\\nIn a recent webinar on [Large Language Models for the\\nEnterprise](https://www.datastax.com/resources/webinar/large-language-models-\\nfor-the-enterprise-chatgpt-and-beyond), we explored how LLMs can be used for\\napplications beyond ChatGPT and how private data needs to be used to augment\\nthe public data that generally available LLMs are trained on. This is where\\nsolutions like LlamaIndex come into play as they provide an orchestration\\nframework for building LLM apps using built-in tools to ingest and query\\nprivate data.\\n\\nCome with us and see how LlamaIndex can be used as a framework for data\\nintegration, data organization, and data retrieval for all your private data\\ngenerative AI needs.\\n\\n## Using LlamaIndex as a Framework for Data Integration\\n\\nAs stated earlier, LlamaIndex is an orchestration framework or â€œdata\\nframeworkâ€ that simplifies building LLM applications. What it provides is the\\nability to perform data augmentation of private data allowing it to be\\nincorporated into LLMs for knowledge generation and reasoning.\\n\\nAt the heart of all generative AI functionality is data. Enterprise\\napplications need to be able to access more than just the public data that\\nLLMs are trained on and need to incorporate structured, unstructured, and\\nsemi-structured data from all their internal and external data sources for\\nbuilding applications.\\n\\nLlamaIndex provides the integration of this data by bringing in data from\\nmultiple unique sources [embedding](https://www.datastax.com/guides/what-is-a-\\nvector-embedding) that data as vectors, and storing that newly vectorized data\\nin a [vector database](https://www.datastax.com/guides/what-is-a-vector-\\ndatabase), allowing for that data to be used by applications to perform\\ncomplex operations with low latency response times like [vector\\nsearch](https://www.datastax.com/guides/what-is-vector-search).\\n\\n### Benefits of LlamaIndex\\n\\n  * Simplified data ingestion connecting existing data sources like APIâ€™s, PDFâ€™s, SQL, NoSQL, documents, etc. for use with LLM applications.\\n  * Natively store and index private data for use across different application use cases, with native integration with downstream vector store/vector databases.\\n  * Built-in query interface, providing the ability to return knowledge-augmented responses from input prompts on your data.\\n\\n### Use Cases for LlamaIndex\\n\\n  * Building natural language chatbots that provide real-time interaction with your product documentation for natural customer engagement.\\n  * Building cognitively aware knowledge agents that can respond to changing decision trees based on a constantly growing knowledge basis.\\n  * Interact with large volumes of structured data using natural language and human interaction.\\n  * Augment public data with private knowledge corpus providing application-specific engagement.\\n\\nReady to unleash the full potential of real-time and generative AI? Discover\\nthe transformative capabilities of Datastax Astra DB and Apache Cassandra for\\nsemantic search. [Learn more about how to unlock the power of Semantic\\nSearch.](https://www.datastax.com/use-cases/vector-search-llm-generative-ai)\\n\\n## How does LlamaIndex Work?\\n\\nLlamaIndex, formerly known as GPT Index, is a framework that provides the\\ntools needed to manage the end-to-end lifecycle for building LLM-based\\napplications. The challenge with building LLM-based applications is that they\\nneed data, typically from multiple different sources, and unless there is\\nstrong adherence to a common data representation the data required is in many\\ndifferent formats, some highly structured, some unstructured, and some in\\nbetween.\\n\\nThat is where LlamaIndex provides the toolbox to unlock this data with tools\\nfor data ingestion and data indexing. Once ingested and indexed, [retrieval\\naugmented generation](https://www.datastax.com/guides/what-is-retrieval-\\naugmented-generation) (RAG) applications can use the LlamaIndex query\\ninterface for accessing that data and powering LLMs.\\n\\n### Ingestion\\n\\nLlamaIndex has 100s of data loaders that provide the ability to connect custom\\ndata sources to LLMs. It connects pre-built solutions like Airtable, Jira,\\nSalesforce and more to generic plugins for loading data from files, JSON\\ndocuments, simple CSV, and unstructured data.\\n\\nA complete list of data loaders can be found on the [Llama\\nHub](https://llamahub.ai/).\\n\\n### Indexing\\n\\nOnce data is ingested, that data needs to be mathematically represented so\\nthat it can be easily queried by an LLM. With LlamaIndex, an index simply\\nprovides the ability to represent data mathematically in multiple different\\ndimensions. Indexing data isnâ€™t a new concept however with machine learning,\\nwe can expand the granularity of indexing from one or two dimensions\\n(key/value representation for example) to hundreds or thousands of dimensions.\\n\\nThe most common approach to indexing data for machine learning and LLMs is\\ncalled a [vector index](https://www.datastax.com/guides/what-is-a-vector-\\nindex) and once data has been indexed the mathematical representation of the\\ndata is called a [vector embedding](https://www.datastax.com/guides/what-is-a-\\nvector-embedding). There are many types of indexing and embedding models but\\nonce data has been embedded the mathematical representation of the data can be\\nused to provide semantic search as things like text with similar meanings will\\nhave a similar mathematical representation. For example, king and queen might\\nbe highly related if the query is royalty but not highly related if the query\\nis gender.\\n\\n### Querying\\n\\nThis is where some of the real power of LlamaIndex and LLMs comes into play\\nbecause querying data using LlamaIndex isnâ€™t a complex series of commands to\\nmerge/join and find the data, it is represented as natural language via a\\nconcept called [prompt engineering](https://www.datastax.com/guides/what-is-\\nprompt-engineering). The simplest way to view interaction with your data once\\nyou have ingested and indexed it is that querying becomes a process of asking\\nquestions and getting responses.\\n\\n## What are the Different Indexes in LlamaIndex?\\n\\nLlamaIndex offers several different indexing models that are designed to\\nprovide optimizations around how you want to explore and categorize your data.\\nThis is ultimately where a lot of gains can be achieved, if you know the type\\nof operation your application needs to perform on the data leveraging a\\nspecific type of index can provide significant benefit to the application\\nusing the LLM and instantiating the query.\\n\\n### List index\\n\\nA list index is an approach that breaks down the data and represents the data\\nin the form of a sequential list. The advantage this has is that while the\\ndata can be explored in a multidimensional manner the primary optimization to\\nquerying the data is via a sequential pattern. This type of index works well\\nwith structured objects that occur over time so things like change logs where\\nyou want to query how things have changed over time.\\n\\n### Tree index\\n\\nWhen using a tree index, LlamaIndex takes the input data and organizes it into\\na binary tree structure where data is organized as parent and leaf nodes. A\\ntree index provides the ability to traverse large amounts of data and\\nconstruct responses where you need to extract specific segments of the texts\\nbased on how the search traverses the tree. Tree indexing works best for cases\\nwhere you have a pattern of information that you want to follow or validate\\nlike building a natural language processing chatbot on top of a support/FAQ\\nengine.\\n\\n### Vector store index\\n\\nWhen using the vector store index type, LlamaIndex stores data notes as vector\\nembeddings. This is probably the most common indexing type as it provides the\\nability to use the representation of the data in multiple different ways\\nincluding [vector or similarity search](https://www.datastax.com/guides/what-\\nis-vector-search). When data is indexed with a vector store index, it can be\\nleveraged locally for smaller datasets and by a single application or for\\nlarger datasets and/or to be used across multiple different LLMs/applications\\nit can be stored in a [high-performance vector\\ndatabase](https://www.datastax.com/guides/what-is-a-vector-database) like\\n[Astra DB](https://www.datastax.com/products/vector-search).\\n\\n### Keyword index\\n\\nKeyword indexing is more of the traditional approach of mapping a metadata\\ntag, i.e. a keyword to specific nodes that contain those keywords. This\\nmapping builds a web of relationships based on keywords, because a keyword may\\nmap to multiple different nodes and a node may be mapped to multiple different\\nkeywords. This indexing model works well if you are looking to tag large\\nvolumes of data and query it based on specific keywords that can be queried\\nacross multiple different datasets. For example legal briefings, medical\\nrecords, or any other data that needs to be aligned based on specific types of\\nmetadata.\\n\\n## On-Demand Webinar: Building an Open Source RAG Application Using LlamaIndex\\n\\nLearn from the experts at DataStax and LlamaIndex about the challenges of\\nbringing an LLM application to production.\\n\\n[Watch Now](https://www.datastax.com/resources/webinar/how-they-built-this-\\ngen-ai-products)\\n\\n[View More Webinars](https://www.datastax.com/resources?page=1&type=webinars)\\n\\n## What is LangChain?\\n\\n[LangChain](https://www.datastax.com/guides/what-is-langchain) is an advanced\\nframework designed to enhance the capabilities of natural language processing.\\nIt achieves this by chaining together different AI language models and tools,\\nallowing for more advanced and nuanced language understanding and generation.\\nThis makes LangChain a significant tool in the development of complex AI\\napplications where sophisticated language skills are essential.\\n\\n![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%272994%27%20height=%272116%27/%3e)![High-\\nlevel view of\\nLangChain](data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7)![High-\\nlevel view of\\nLangChain](https://cdn.sanity.io/images/bbnkhnhl/production/cebf411f306309d008a863e47b553a2c9114b916-2994x2116.jpg?w=3840&q=75&fit=clip&auto=format)High-\\nlevel view of LangChain\\n\\nThe framework\\'s modular approach provides flexibility, enabling developers to\\ncreate customized solutions for a variety of language processing tasks. From\\ngenerating human-like text to sophisticated data analysis, LangChain\\'s\\nintegration of multiple AI components opens up new possibilities in AI\\ndevelopment and application, making it a key player in the evolving landscape\\nof artificial intelligence.\\n\\n## LlamaIndex vs LangChain: Key Comparisons\\n\\nOne of the big questions that come up is how do LlamaIndex and LangChain\\ncompare, do they provide similar functionality or do they complement each\\nother? The reality is that LlamaIndex and LangChain provide two different\\nsides to the same coin. While they are both designed to provide an interface\\nto LLMs and machine learning in your application, LlamaIndex is designed and\\nbuilt specifically to provide indexing and querying capabilities for\\nintelligent searching of data. On the other side of that coin is the ability\\nto interact with data either via natural language processing, i.e. building a\\nchatbot to interact with your data, or using that data to drive other\\nfunctions like calling code.\\n\\nLlamaIndex provides the ability to store the data you have in a variety of\\ndifferent formats and pull that data from a bunch of different sources,\\nultimately providing the how for your generative AI application.\\n\\nLangChain provides the ability to do something with that data once it has been\\nstored, generate code, provide generative question answers, and drive\\ndecisions, ultimately providing the what for your generative AI application.\\n\\n## What Different Projects Can You Make with LlamaIndex?\\n\\nWith LlamaIndex you have an easy-to-use data/orchestration framework for\\ningesting, indexing, and querying your data for building generative AI\\napplications. While we provide a simple example above to get started, the real\\npower of LlamaIndex comes from the ability to build data-driven AI\\napplications. You donâ€™t need to retrain models, you can use LlamaIndex, and a\\nhighly scalable vector database to create custom query engines, conversational\\nchatbots, or powerful agents that can interact with complex problem-solving by\\ndynamically interpreting the data coming in and making contextual decisions in\\nreal-time.\\n\\n## Building an Open Source RAG Application Using LlamaIndex\\n\\nLearn how to build a knowledge retrieval chatbot in production using\\nLlamaIndex with this free on-demand workshop.\\n\\n[Watch the Recording](https://www.datastax.com/resources/webinar/building-an-\\nopen-source-rag-application-using-llamaindex)\\n\\n[View More Webinars](https://www.datastax.com/resources?page=1&type=webinars)\\n\\n## What are the Potential Challenges and Limitations of LlamaIndex?\\n\\nWhile LlamaIndex offers powerful capabilities in data indexing and retrieval,\\nit\\'s important to be aware of its potential challenges and limitations. Here\\nare some specific challenges you might encounter:\\n\\n### Data Volume and Indexing Speed\\n\\nHandling large volumes of data can be challenging. LlamaIndex may face\\ndifficulties in quickly indexing extensive datasets, affecting the efficiency\\nof data retrieval.\\n\\n### Integration Complexity\\n\\nIntegrating LlamaIndex with existing systems or various data sources can be\\ncomplex. Ensuring seamless integration often requires technical expertise and\\ncan be time-consuming.\\n\\n### Accuracy and Relevance of Results\\n\\nEnsuring the accuracy and relevance of search results is a critical challenge.\\nFine-tuning LlamaIndex to return the most relevant results based on specific\\nqueries requires careful configuration and continuous optimization.\\n\\n### Scalability\\n\\nAs the volume of data grows, scaling LlamaIndex to maintain performance\\nwithout significant resource allocation can be challenging.\\n\\n### Maintenance and Updates\\n\\nRegular maintenance and updates are crucial for LlamaIndex to function\\neffectively. Keeping up with the latest updates and ensuring compatibility\\nwith other system components can be demanding.\\n\\n## Build real-time, Generative AI Apps with Vector Search on Datastax Astra DB\\n\\nSo when it comes time to [build a generative AI\\napplication](https://www.datastax.com/use-cases/vector-search-llm-generative-\\nai) that needs the ability to leverage your private data and incorporate that\\ninto an application\\'s ability to interact and respond to that data, LlamaIndex\\nis a great place to start for ingestion, indexing, and querying. But donâ€™t\\nrepeat the mistakes of the past and silo the data you are using, embedding,\\nand accessing for AI applications. Build out a complete end-to-end solution\\nthat includes storing those embeddings and indexes in a highly scalable vector\\nstore like Astra DB.\\n\\n![](data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%271440%27%20height=%27802%27/%3e)![Datastax\\nAstraDB LlamaIndex\\nIntegration](data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7)![Datastax\\nAstraDB LlamaIndex\\nIntegration](https://cdn.sanity.io/images/bbnkhnhl/production/f0cc61cc2746197852a2defd8f8c4e29918ea1b7-1440x802.png?w=3840&q=75&fit=clip&auto=format)\\n\\nTo get started with LlamaIndex and to see how Datastax and LlamaIndex are\\nbetter together check out our recent blog post on [Building Petabyte-Scale\\nGenAI Apps Just Got Easier](https://www.datastax.com/blog/llamaindex-and-\\nastra-db-building-petabyte-scale-genai-apps-just-got-easier).\\n\\nAlso, you can find more information on how to set up and deploy Astra DB on\\none of the [worldâ€™s highest performing Vector\\nStores](https://www.datastax.com/products/datastax-\\nastra?utm_source=llamaindex_guide&utm_medium=guide&utm_campaign=guidepillar)\\nbuilt on Apache Cassandra which was designed for handling massive volumes of\\ndata at scale. To get started for free, [register\\nhere](https://astra.datastax.com/register?utm_source=llamaindex_guide&utm_medium=guide&utm_campaign=guidepillar).\\n\\nDatastax provides the real-time vector data and RAG capabilities that Gen AI\\napps need, with seamless integration with developersâ€™ stacks of choice ( _RAG,\\nLangchain, LlamaIndex, OpenAI, GCP, AWS, Azure, etc_ )\\n\\n[Subscribe to the RSS Feed](/guides/rss.xml)\\n\\n## Build generative AI apps at scale on Astra DB\\n\\nAstra DB gives developers the APIs, real-time data and complete ecosystem\\nintegrations to put accurate Gen AI apps in production - FAST.\\n\\n[Learn More](https://www.datastax.com/products/vector-search)\\n\\n[Get Started for Free](https://astra.datastax.com/signup?utm_source=website)\\n\\n##### Share\\n\\n[](http://www.facebook.com/sharer.php?u=https://www.datastax.com/ko/guides/what-\\nis-llamaindex&p\\\\[title\\\\]=What is LlamaIndex? Exploring LLM Orchestration\\nFrameworks)[](http://twitter.com/share?text=What is LlamaIndex? Exploring LLM\\nOrchestration Frameworks&url=https://www.datastax.com/ko/guides/what-is-\\nllamaindex)[](https://www.linkedin.com/shareArticle?mini=true&url=https://www.datastax.com/ko/guides/what-\\nis-llamaindex&title=What is LlamaIndex? Exploring LLM Orchestration\\nFrameworks)[](https://news.ycombinator.com/submitlink?u=https://www.datastax.com/ko/guides/what-\\nis-llamaindex)\\n\\nJUMP TO SECTION\\n\\n## [What is LlamaIndex? ](/ko/guides/what-is-llamaindex#what-is-llamaindex)\\n\\n## [Using LlamaIndex as a Framework for Data Integration](/ko/guides/what-is-\\nllamaindex#using-llamaindex-as-a-framework-for-data-integration)\\n\\n### [Benefits of LlamaIndex](/ko/guides/what-is-llamaindex#benefits-of-\\nllamaindex)\\n\\n### [Use Cases for LlamaIndex](/ko/guides/what-is-llamaindex#use-cases-for-\\nllamaindex)\\n\\n## [How does LlamaIndex Work?](/ko/guides/what-is-llamaindex#how-does-\\nllamaindex-work)\\n\\n### [Ingestion](/ko/guides/what-is-llamaindex#ingestion)\\n\\n### [Indexing](/ko/guides/what-is-llamaindex#indexing)\\n\\n### [Querying](/ko/guides/what-is-llamaindex#querying)\\n\\n## [What are the Different Indexes in LlamaIndex?](/ko/guides/what-is-\\nllamaindex#what-are-the-different-indexes-in-llamaindex)\\n\\n### [List index](/ko/guides/what-is-llamaindex#list-index)\\n\\n### [Tree index](/ko/guides/what-is-llamaindex#tree-index)\\n\\n### [Vector store index](/ko/guides/what-is-llamaindex#vector-store-index)\\n\\n### [Keyword index](/ko/guides/what-is-llamaindex#keyword-index)\\n\\n## [What is LangChain?](/ko/guides/what-is-llamaindex#what-is-langchain)\\n\\n## [LlamaIndex vs LangChain: Key Comparisons](/ko/guides/what-is-\\nllamaindex#llamaindex-vs-langchain-key-comparisons)\\n\\n## [What Different Projects Can You Make with LlamaIndex?](/ko/guides/what-is-\\nllamaindex#what-different-projects-can-you-make-with-llamaindex)\\n\\n## [What are the Potential Challenges and Limitations of\\nLlamaIndex?](/ko/guides/what-is-llamaindex#what-are-the-potential-challenges-\\nand-limitations-of-llamaindex)\\n\\n### [Data Volume and Indexing Speed](/ko/guides/what-is-llamaindex#data-\\nvolume-and-indexing-speed)\\n\\n### [Integration Complexity](/ko/guides/what-is-llamaindex#integration-\\ncomplexity)\\n\\n### [Accuracy and Relevance of Results](/ko/guides/what-is-\\nllamaindex#accuracy-and-relevance-of-results)\\n\\n### [Scalability](/ko/guides/what-is-llamaindex#scalability)\\n\\n### [Maintenance and Updates](/ko/guides/what-is-llamaindex#maintenance-and-\\nupdates)\\n\\n## [Build real-time, Generative AI Apps with Vector Search on Datastax Astra\\nDB](/ko/guides/what-is-llamaindex#build-real-time-generative-ai-apps-with-\\nvector-search-on-datastax-astra-db)\\n\\n##### Share\\n\\n[](http://www.facebook.com/sharer.php?u=https://www.datastax.com/ko/guides/what-\\nis-llamaindex&p\\\\[title\\\\]=What is LlamaIndex? Exploring LLM Orchestration\\nFrameworks)[](http://twitter.com/share?text=What is LlamaIndex? Exploring LLM\\nOrchestration Frameworks&url=https://www.datastax.com/ko/guides/what-is-\\nllamaindex)[](https://www.linkedin.com/shareArticle?mini=true&url=https://www.datastax.com/ko/guides/what-\\nis-llamaindex&title=What is LlamaIndex? Exploring LLM Orchestration\\nFrameworks)[](https://news.ycombinator.com/submitlink?u=https://www.datastax.com/ko/guides/what-\\nis-llamaindex)\\n\\n##### More Guides\\n\\n[View All](/ko/guides)\\n\\n[![What is the nearest neighbor algorithm? Method &\\nExamples](https://cdn.sanity.io/images/bbnkhnhl/production/ac8f31201408a19766f50e547aff094d00652686-768x526.png?w=1920&q=75&fit=clip&auto=format)Guide\\n\\n###### What is the nearest neighbor algorithm? Method & Examples\\n\\n](/ko/guides/what-is-nearest-neighbor)\\n\\n[![Understanding Hierarchical Navigable Small Worlds \\\\(HNSW\\\\)\\n](https://cdn.sanity.io/images/bbnkhnhl/production/d83c32aada00637541dcaa76e55eb2d4e67f92dc-1104x640.jpg?w=3840&q=75&fit=clip&auto=format)Guide\\n\\n###### Understanding Hierarchical Navigable Small Worlds (HNSW)\\n\\n](/ko/guides/hierarchical-navigable-small-worlds)\\n\\n[![Understanding the Real-World Applications of Cosine\\nSimilarity](https://cdn.sanity.io/images/bbnkhnhl/production/d83c32aada00637541dcaa76e55eb2d4e67f92dc-1104x640.jpg?w=3840&q=75&fit=clip&auto=format)Guide\\n\\n###### Understanding the Real-World Applications of Cosine Similarity\\n\\n](/ko/guides/real-world-applications-of-cosine-similarity)\\n\\n[![What is LangChain? Getting Started with\\nLangChain](https://cdn.sanity.io/images/bbnkhnhl/production/534c5e44e2186c766c6190f181fe63c436717b9d-672x672.png?w=1920&q=75&fit=clip&auto=format)Guide\\n\\n###### What is LangChain? Getting Started with LangChain\\n\\n](/ko/guides/what-is-langchain)\\n\\n## One-stop Data API for Production GenAI\\n\\nAstra DB gives JavaScript developers a complete data API and out-of-the-box\\nintegrations that make it easier to build production RAG apps with high\\nrelevancy and low latency.\\n\\n[Get started for free](https://astra.datastax.com/signup?utm_source=website)\\n\\n[Schedule a demo](/ko/products/astra/demo)\\n\\nCompany[About Us](/ko/company)[Leadership](/ko/our-people)[Board of\\nDirectors](/ko/company/board-of-directors)[Contact Us](/ko/contact-\\nus)[Partners](/ko/partners/directory)[Careers](/ko/company/careers)[Newsroom](/ko/resources/news)\\n\\nResources[Blog](/ko/blog)[Events](/ko/events)[eBooks](/ko/resources?type=ebook)[Whitepapers](/ko/resources?type=whitepapers)[Webinars](/ko/resources?type=webinar)[Legal](/ko/legal)[Security](/ko/products/datastax-\\nenterprise/security-assurance)[Awesome Astra](https://awesome-\\nastra.github.io/docs/)\\n\\nCloud Partners[Amazon Web Services](/ko/platform/amazon-web-services)[Google\\nCloud Platform](/ko/platform/google-cloud-platform)[Microsoft\\nAzure](/ko/platform/microsoft-azure)\\n\\nÂ© 2024 DataStax[Privacy Policy](/ko/legal/datastax-website-privacy-\\npolicy)[Terms of Use](/ko/legal/datastax-website-terms-use)[Trademark\\nNotice](/ko/legal/datastax-trademark-notice)[Brand Resources](/ko/brand-\\nresources)Do Not Sell My Info\\n\\nDataStax, is a registered trademark of DataStax, Inc.. Apache, Apache\\nCassandra, Cassandra, Apache Pulsar, and Pulsar are either registered\\ntrademarks or trademarks of the Apache Software Foundation.\\n\\n[![](https://cdn.sanity.io/images/bbnkhnhl/production/8ce5879a6fdfda3267ac087906a03d2ce3182094-32x32.svg?w=64&q=75&fit=clip&auto=format)](https://www.facebook.com/datastax\\n\"https://www.facebook.com/datastax\")[![](https://cdn.sanity.io/images/bbnkhnhl/production/f39a8e0412d732fcfbf8e166b9fc2b5c0ab62ff8-32x33.svg?w=64&q=75&fit=clip&auto=format)](https://twitter.com/datastax\\n\"https://twitter.com/datastax\")[![](https://cdn.sanity.io/images/bbnkhnhl/production/d96e639a2bf940cd885a5c56679cd287d8f7b903-32x32.svg?w=64&q=75&fit=clip&auto=format)](https://www.linkedin.com/company/datastax/\\n\"https://www.linkedin.com/company/datastax/\")[![](https://cdn.sanity.io/images/bbnkhnhl/production/ad8620a9e1b21c1c982e43642cb4de21d3d19eb9-32x32.svg?w=64&q=75&fit=clip&auto=format)](https://github.com/datastax/\\n\"https://github.com/datastax/\")[![](https://cdn.sanity.io/images/bbnkhnhl/production/dd43439c38fe31a6213e46a6b9aae6ff4db76794-32x32.svg?w=64&q=75&fit=clip&auto=format)](https://datastax.medium.com/\\n\"https://datastax.medium.com/\")[![](https://cdn.sanity.io/images/bbnkhnhl/production/e453f185aeb071f0923eceed1818a0d48f06e963-32x32.svg?w=64&q=75&fit=clip&auto=format)](https://www.twitch.tv/datastaxdevs\\n\"https://www.twitch.tv/datastaxdevs\")\\n\\n###### Korea\\n\\n', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "documents[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26854cc3-af61-4910-ab6b-3bed6acfb447",
      "metadata": {
        "id": "26854cc3-af61-4910-ab6b-3bed6acfb447"
      },
      "outputs": [],
      "source": [
        "index = SummaryIndex.from_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cfdf87a-97cb-481f-ad51-be5bf8b5217f",
      "metadata": {
        "id": "5cfdf87a-97cb-481f-ad51-be5bf8b5217f"
      },
      "outputs": [],
      "source": [
        "# set Logging to DEBUG for more detailed outputs\n",
        "query_engine = index.as_query_engine()\n",
        "response = query_engine.query(\"What is LlamaIndex?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7278d033-cae3-4ddf-96bd-75ea570ca53f",
      "metadata": {
        "id": "7278d033-cae3-4ddf-96bd-75ea570ca53f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "8e1fbbc7-e2c8-4504-f38f-7db734a2ae61"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<b>LlamaIndex is a crucial tool in the realm of artificial intelligence, providing a platform for integrating private and public data to develop applications that utilize Large Language Models (LLMs). It simplifies the tasks of data ingestion, indexing, and querying, acting as a versatile resource for generative AI applications.</b>"
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(Markdown(f\"<b>{response}</b>\"))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "vscode": {
      "interpreter": {
        "hash": "c32397a35d2e76e766f80c3872b208f0c0029e8a6a9b8e2a8fe7b1641cfa009b"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}